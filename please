
# --- 2. Define Time Periods ---
print("--- Defining Time Periods ---")
tariff_date = pd.Timestamp('2025-04-02')
pre_days = 30
post_days = 30

all_business_days = pd.date_range(start='2023-01-01', end='2025-05-29', freq='B')
tariff_idx = all_business_days.get_loc(tariff_date)

pre_2025_start_idx = max(0, tariff_idx - pre_days)
pre_2025_start_date = all_business_days[pre_2025_start_idx]
pre_2025_end_date = tariff_date - pd.Timedelta(days=1)

post_2025_end_idx = min(len(all_business_days) - 1, tariff_idx + post_days - 1)
post_2025_end_date = all_business_days[post_2025_end_idx]
post_2025_start_date = tariff_date

pre_2024_start_date = pre_2025_start_date - pd.DateOffset(years=1)
pre_2024_end_date = pre_2025_end_date - pd.DateOffset(years=1)
post_2024_start_date = post_2025_start_date - pd.DateOffset(years=1)
post_2024_end_date = post_2025_end_date - pd.DateOffset(years=1)

periods = {
    'pre_2025': (pre_2025_start_date, pre_2025_end_date),
    'post_2025': (post_2025_start_date, post_2025_end_date),
    'pre_2024': (pre_2024_start_date, pre_2024_end_date),
    'post_2024': (post_2024_start_date, post_2024_end_date),
}

for name, (start, end) in periods.items():
    print(f"{name.replace('_', ' ').title()}: {start.date()} to {end.date()}")

# --- 3. OPTIMIZED: Single Aggregation for All Analyses ---
print("\n--- Optimized Aggregation for All Analyses ---")
start_time = time.time()

# Create period indicators for efficient filtering
def assign_period(date):
    for period_name, (start_date, end_date) in periods.items():
        if start_date <= date <= end_date:
            return period_name
    return None

# Filter data to only relevant periods first
df_filtered = df[df['Date'].apply(assign_period).notna()].copy()
df_filtered['Period'] = df_filtered['Date'].apply(assign_period)

print(f"Filtered data from {len(df)} to {len(df_filtered)} rows for analysis periods")

# Single comprehensive aggregation
# Group by Customer, Period, Security_Type, and Industry to get all combinations at once
agg_data = df_filtered.groupby([
    'Customer_Name', 'Customer_Industry', 'Period', 'Security_Type'
])['Amount'].sum().reset_index()

print(f"Aggregation completed in {time.time() - start_time:.2f} seconds")

# --- 4. Overall Net Buy Analysis (Same as before) ---
print("\n--- 4. Overall Net Buy Analysis ---")

# Pivot to get customer-period level data
customer_period = df_filtered.groupby(['Customer_Name', 'Period'])['Amount'].sum().reset_index()
customer_period_pivot = customer_period.pivot(index='Customer_Name', columns='Period', values='Amount').fillna(0)

# Calculate changes
customer_period_pivot['Change_2025'] = customer_period_pivot['post_2025'] - customer_period_pivot['pre_2025']
customer_period_pivot['Change_2024'] = customer_period_pivot['post_2024'] - customer_period_pivot['pre_2024']

# Statistical tests
t_stat, p_value = stats.ttest_ind(customer_period_pivot['Change_2025'], 
                                  customer_period_pivot['Change_2024'], 
                                  equal_var=False)

# Descriptive statistics for intuitive interpretation
avg_pre_2025 = customer_period_pivot['pre_2025'].mean()
avg_post_2025 = customer_period_pivot['post_2025'].mean()
avg_change_2025 = customer_period_pivot['Change_2025'].mean()
avg_change_2024 = customer_period_pivot['Change_2024'].mean()

print("=== OVERALL NET BUY SUMMARY ===")
print(f"2025 Before Tariff (Average): ${avg_pre_2025:,.0f}")
print(f"2025 After Tariff (Average): ${avg_post_2025:,.0f}")
print(f"2025 Change (After - Before): ${avg_change_2025:,.0f}")
print(f"2024 Change (Same Period): ${avg_change_2024:,.0f}")
print(f"DiD Effect (2025 Change - 2024 Change): ${avg_change_2025 - avg_change_2024:,.2f}")
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Conclusion: Significant change in net buy post-tariff beyond seasonal trends.")
else:
    print("Conclusion: No significant difference beyond normal seasonality.")

# --- 5. OPTIMIZED Security Type Analysis ---
print("\n--- 5. Optimized Security Type Analysis ---")
start_time = time.time()

# Pivot aggregated data to get customer-period-security level
sec_pivot = agg_data.pivot_table(
    index=['Customer_Name'], 
    columns=['Period', 'Security_Type'], 
    values='Amount', 
    fill_value=0
)

# Get all unique customers for consistent indexing
all_customers = customer_period_pivot.index

security_type_results = []

for sec_type in security_types:
    try:
        # Create DataFrame with proper index from all customers
        sec_data_dict = {}
        
        for period in ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']:
            if ('Period' in sec_pivot.columns.names and 'Security_Type' in sec_pivot.columns.names and 
                (period, sec_type) in sec_pivot.columns):
                sec_data_dict[period] = sec_pivot[(period, sec_type)]
            else:
                # Create a Series with zeros for all customers
                sec_data_dict[period] = pd.Series(0, index=all_customers)
        
        sec_data = pd.DataFrame(sec_data_dict)
        
        sec_data['Change_2025'] = sec_data['post_2025'] - sec_data['pre_2025']
        sec_data['Change_2024'] = sec_data['post_2024'] - sec_data['pre_2024']
        
        # Filter active customers for this security type
        active_mask = (sec_data[['pre_2024', 'post_2024', 'pre_2025', 'post_2025']] != 0).any(axis=1)
        active_sec_data = sec_data[active_mask]
        
        # Calculate descriptive statistics for interpretation
        avg_pre_2025_sec = active_sec_data['pre_2025'].mean()
        avg_post_2025_sec = active_sec_data['post_2025'].mean()
        avg_change_2025_sec = active_sec_data['Change_2025'].mean()
        avg_change_2024_sec = active_sec_data['Change_2024'].mean()
        
        if len(active_sec_data) > 1:
            t_stat, p_value = stats.ttest_ind(active_sec_data['Change_2025'], 
                                              active_sec_data['Change_2024'], 
                                              equal_var=False)
            did_effect = avg_change_2025_sec - avg_change_2024_sec
        else:
            t_stat, p_value, did_effect = np.nan, np.nan, 0
            
        security_type_results.append({
            'Security_Type': sec_type,
            'Pre_2025_Avg': avg_pre_2025_sec,
            'Post_2025_Avg': avg_post_2025_sec,
            'Change_2025_Avg': avg_change_2025_sec,
            'Change_2024_Avg': avg_change_2024_sec,
            'DiD_Effect_Mean': did_effect,
            'T_Statistic': t_stat,
            'P_Value': p_value,
            'Active_Customers': len(active_sec_data)
        })
        
    except Exception as e:
        print(f"Error processing {sec_type}: {e}")
        security_type_results.append({
            'Security_Type': sec_type,
            'Pre_2025_Avg': 0,
            'Post_2025_Avg': 0,
            'Change_2025_Avg': 0,
            'Change_2024_Avg': 0,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })

print("\n=== SECURITY TYPE DETAILED RESULTS ===")
sec_results_df = pd.DataFrame(security_type_results)
print(sec_results_df[['Security_Type', 'Pre_2025_Avg', 'Post_2025_Avg', 'Change_2025_Avg', 'DiD_Effect_Mean', 'P_Value', 'Active_Customers']].round(0))

print("\nSecurity Type Interpretations:")
for _, row in sec_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        direction = "increased" if row['Change_2025_Avg'] > 0 else "decreased"
        print(f"  - {row['Security_Type']}: SIGNIFICANT IMPACT")
        print(f"    • Before Tariff: ${row['Pre_2025_Avg']:,.0f} | After Tariff: ${row['Post_2025_Avg']:,.0f}")
        print(f"    • Net buy {direction} by ${abs(row['Change_2025_Avg']):,.0f} (DiD: ${row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Security_Type']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Security_Type']}: No significant impact (p={row['P_Value']:.4f})")

# --- 6. OPTIMIZED Industry Analysis ---
print("\n--- 6. Optimized Industry Analysis ---")
start_time = time.time()

# Get customer-industry mapping - handle potential duplicates
customer_industry_df = df[['Customer_Name', 'Customer_Industry']].drop_duplicates()

# Check for customers with multiple industries (data quality issue)
customer_counts = customer_industry_df['Customer_Name'].value_counts()
if (customer_counts > 1).any():
    print(f"Warning: {(customer_counts > 1).sum()} customers have multiple industries. Using first occurrence.")
    # Keep only the first occurrence for each customer
    customer_industry_df = customer_industry_df.drop_duplicates(subset=['Customer_Name'], keep='first')

customer_industry_map = customer_industry_df.set_index('Customer_Name')['Customer_Industry']

# Add industry info to customer_period_pivot
customer_period_with_industry = customer_period_pivot.copy()
customer_period_with_industry = customer_period_with_industry.reset_index()  # Reset index to make Customer_Name a column
customer_period_with_industry['Industry'] = customer_period_with_industry['Customer_Name'].map(customer_industry_map)

industry_results = []

for industry in industries:
    industry_data = customer_period_with_industry[customer_period_with_industry['Industry'] == industry]
    
    if len(industry_data) == 0:
        industry_results.append({
            'Industry': industry,
            'Pre_2025_Avg': 0,
            'Post_2025_Avg': 0,
            'Change_2025_Avg': 0,
            'Change_2024_Avg': 0,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })
        continue
    
    # Filter active customers
    active_cols = ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']
    active_mask = (industry_data[active_cols] != 0).any(axis=1)
    active_industry_data = industry_data[active_mask]
    
    # Calculate descriptive statistics
    avg_pre_2025_ind = active_industry_data['pre_2025'].mean() if len(active_industry_data) > 0 else 0
    avg_post_2025_ind = active_industry_data['post_2025'].mean() if len(active_industry_data) > 0 else 0
    avg_change_2025_ind = active_industry_data['Change_2025'].mean() if len(active_industry_data) > 0 else 0
    avg_change_2024_ind = active_industry_data['Change_2024'].mean() if len(active_industry_data) > 0 else 0
    
    if len(active_industry_data) > 1:
        t_stat, p_value = stats.ttest_ind(active_industry_data['Change_2025'], 
                                          active_industry_data['Change_2024'], 
                                          equal_var=False)
        did_effect = avg_change_2025_ind - avg_change_2024_ind
    else:
        t_stat, p_value, did_effect = np.nan, np.nan, 0
        
    industry_results.append({
        'Industry': industry,
        'Pre_2025_Avg': avg_pre_2025_ind,
        'Post_2025_Avg': avg_post_2025_ind,
        'Change_2025_Avg': avg_change_2025_ind,
        'Change_2024_Avg': avg_change_2024_ind,
        'DiD_Effect_Mean': did_effect,
        'T_Statistic': t_stat,
        'P_Value': p_value,
        'Active_Customers': len(active_industry_data)
    })

ind_results_df = pd.DataFrame(industry_results)
print(f"Industry analysis completed in {time.time() - start_time:.2f} seconds")
print(ind_results_df.round(4))

print("\nIndustry Interpretations:")
for _, row in ind_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Industry']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Industry']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Industry']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

print("\n--- Analysis Complete ---")




#### NEW
import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.formula.api as smf
import time

# --- 1. Regenerate Dummy Data (Your provided code) ---
# Generate date ranges
start_date = '2023-01-01'
end_date = '2025-05-29'
dates = pd.date_range(start=start_date, end=end_date, freq='B')  # Business days only

# Key events
tariff_date = pd.Timestamp('2025-04-02')

# Customer and security setup
n_customers = 500
customers = [f'Customer_{i:03d}' for i in range(n_customers)]
industries = ['Technology', 'Manufacturing', 'Finance', 'Retail', 'Healthcare',
              'Energy', 'Real Estate', 'Consumer Goods']
security_types = ['Foreign Stocks', 'Local Stocks', 'Bonds', 'Certificate of Deposit',
                  'Unit Trusts', 'ETFs']

# Generate trades
trades = []
for date in dates:
    # Adjust trading patterns based on events
    if date >= tariff_date:
        foreign_bias = 0.25
        volume_multiplier = 1.3
        bond_bias = 0.2
    elif date >= pd.Timestamp('2025-01-01'):
        foreign_bias = 0.45
        volume_multiplier = 1.1
        bond_bias = 0.1
    else:
        foreign_bias = 0.5
        volume_multiplier = 1.0
        bond_bias = 0.05

    n_trades = np.random.poisson(200 * volume_multiplier)

    for _ in range(n_trades):
        customer = np.random.choice(customers)
        industry = np.random.choice(industries)

        security_probs = {
            'Foreign Stocks': foreign_bias,
            'Local Stocks': 0.4 - (foreign_bias - 0.25),
            'Bonds': bond_bias,
            'Certificate of Deposit': 0.05,
            'Unit Trusts': 0.03,
            'ETFs': 0.02
        }
        sum_probs = sum(security_probs.values())
        security_probs = {k: v / sum_probs for k, v in security_probs.items()}

        security_type = np.random.choice(list(security_probs.keys()), p=list(security_probs.values()))

        if np.random.rand() < 0.55:
            investment_amount = np.random.lognormal(10, 1.5) * 1000
        else:
            investment_amount = -(np.random.lognormal(10, 1.5) * 1000)

        trades.append({
            'Date': date,
            'Customer_Name': customer,
            'Customer_Industry': industry,
            'Amount': investment_amount,
            'Security_Type': security_type
        })

df = pd.DataFrame(trades)
df['Date'] = pd.to_datetime(df['Date'])
print(f"Total trades generated: {len(df)}")
print(f"Data range: {df['Date'].min().date()} to {df['Date'].max().date()}\n")

# --- 2. Define Time Periods ---
print("--- Defining Time Periods ---")
tariff_date = pd.Timestamp('2025-04-02')
pre_days = 30
post_days = 30

all_business_days = pd.date_range(start='2023-01-01', end='2025-05-29', freq='B')
tariff_idx = all_business_days.get_loc(tariff_date)

pre_2025_start_idx = max(0, tariff_idx - pre_days)
pre_2025_start_date = all_business_days[pre_2025_start_idx]
pre_2025_end_date = tariff_date - pd.Timedelta(days=1)

post_2025_end_idx = min(len(all_business_days) - 1, tariff_idx + post_days - 1)
post_2025_end_date = all_business_days[post_2025_end_idx]
post_2025_start_date = tariff_date

pre_2024_start_date = pre_2025_start_date - pd.DateOffset(years=1)
pre_2024_end_date = pre_2025_end_date - pd.DateOffset(years=1)
post_2024_start_date = post_2025_start_date - pd.DateOffset(years=1)
post_2024_end_date = post_2025_end_date - pd.DateOffset(years=1)

periods = {
    'pre_2025': (pre_2025_start_date, pre_2025_end_date),
    'post_2025': (post_2025_start_date, post_2025_end_date),
    'pre_2024': (pre_2024_start_date, pre_2024_end_date),
    'post_2024': (post_2024_start_date, post_2024_end_date),
}

for name, (start, end) in periods.items():
    print(f"{name.replace('_', ' ').title()}: {start.date()} to {end.date()}")

# --- 3. OPTIMIZED: Single Aggregation for All Analyses ---
print("\n--- Optimized Aggregation for All Analyses ---")
start_time = time.time()

# Create period indicators for efficient filtering
def assign_period(date):
    for period_name, (start_date, end_date) in periods.items():
        if start_date <= date <= end_date:
            return period_name
    return None

# Filter data to only relevant periods first
df_filtered = df[df['Date'].apply(assign_period).notna()].copy()
df_filtered['Period'] = df_filtered['Date'].apply(assign_period)

print(f"Filtered data from {len(df)} to {len(df_filtered)} rows for analysis periods")

# Single comprehensive aggregation
# Group by Customer, Period, Security_Type, and Industry to get all combinations at once
agg_data = df_filtered.groupby([
    'Customer_Name', 'Customer_Industry', 'Period', 'Security_Type'
])['Amount'].sum().reset_index()

print(f"Aggregation completed in {time.time() - start_time:.2f} seconds")

# --- 4. Overall Net Buy Analysis (Same as before) ---
print("\n--- 4. Overall Net Buy Analysis ---")

# Pivot to get customer-period level data
customer_period = df_filtered.groupby(['Customer_Name', 'Period'])['Amount'].sum().reset_index()
customer_period_pivot = customer_period.pivot(index='Customer_Name', columns='Period', values='Amount').fillna(0)

# Calculate changes
customer_period_pivot['Change_2025'] = customer_period_pivot['post_2025'] - customer_period_pivot['pre_2025']
customer_period_pivot['Change_2024'] = customer_period_pivot['post_2024'] - customer_period_pivot['pre_2024']

# Statistical tests
t_stat, p_value = stats.ttest_ind(customer_period_pivot['Change_2025'], 
                                  customer_period_pivot['Change_2024'], 
                                  equal_var=False)

print(f"DiD (2025 Change - 2024 Change) - Mean difference: {customer_period_pivot['Change_2025'].mean() - customer_period_pivot['Change_2024'].mean():,.2f}")
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Conclusion: Significant change in net buy post-tariff beyond seasonal trends.")
else:
    print("Conclusion: No significant difference beyond normal seasonality.")

# --- 5. OPTIMIZED Security Type Analysis ---
print("\n--- 5. Optimized Security Type Analysis ---")
start_time = time.time()

# Pivot aggregated data to get customer-period-security level
sec_pivot = agg_data.pivot_table(
    index=['Customer_Name'], 
    columns=['Period', 'Security_Type'], 
    values='Amount', 
    fill_value=0
)

security_type_results = []

for sec_type in security_types:
    try:
        # Extract data for this security type
        sec_data = pd.DataFrame({
            'pre_2024': sec_pivot[('pre_2024', sec_type)] if ('pre_2024', sec_type) in sec_pivot.columns else 0,
            'post_2024': sec_pivot[('post_2024', sec_type)] if ('post_2024', sec_type) in sec_pivot.columns else 0,
            'pre_2025': sec_pivot[('pre_2025', sec_type)] if ('pre_2025', sec_type) in sec_pivot.columns else 0,
            'post_2025': sec_pivot[('post_2025', sec_type)] if ('post_2025', sec_type) in sec_pivot.columns else 0,
        })
        
        sec_data['Change_2025'] = sec_data['post_2025'] - sec_data['pre_2025']
        sec_data['Change_2024'] = sec_data['post_2024'] - sec_data['pre_2024']
        
        # Filter active customers for this security type
        active_mask = (sec_data[['pre_2024', 'post_2024', 'pre_2025', 'post_2025']] != 0).any(axis=1)
        active_sec_data = sec_data[active_mask]
        
        if len(active_sec_data) > 1:
            t_stat, p_value = stats.ttest_ind(active_sec_data['Change_2025'], 
                                              active_sec_data['Change_2024'], 
                                              equal_var=False)
            did_effect = active_sec_data['Change_2025'].mean() - active_sec_data['Change_2024'].mean()
        else:
            t_stat, p_value, did_effect = np.nan, np.nan, 0
            
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': did_effect,
            'T_Statistic': t_stat,
            'P_Value': p_value,
            'Active_Customers': len(active_sec_data)
        })
        
    except Exception as e:
        print(f"Error processing {sec_type}: {e}")
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })

sec_results_df = pd.DataFrame(security_type_results)
print(f"Security type analysis completed in {time.time() - start_time:.2f} seconds")
print(sec_results_df.round(4))

print("\nSecurity Type Interpretations:")
for _, row in sec_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Security_Type']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Security_Type']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Security_Type']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")




# --- 6. OPTIMIZED Industry Analysis ---
print("\n--- 6. Optimized Industry Analysis ---")
start_time = time.time()

# Get customer-industry mapping - handle potential duplicates
customer_industry_df = df[['Customer_Name', 'Customer_Industry']].drop_duplicates()

# Check for customers with multiple industries (data quality issue)
customer_counts = customer_industry_df['Customer_Name'].value_counts()
if (customer_counts > 1).any():
    print(f"Warning: {(customer_counts > 1).sum()} customers have multiple industries. Using first occurrence.")
    # Keep only the first occurrence for each customer
    customer_industry_df = customer_industry_df.drop_duplicates(subset=['Customer_Name'], keep='first')

customer_industry_map = customer_industry_df.set_index('Customer_Name')['Customer_Industry']

# Add industry info to customer_period_pivot
customer_period_with_industry = customer_period_pivot.copy()
customer_period_with_industry = customer_period_with_industry.reset_index()  # Reset index to make Customer_Name a column
customer_period_with_industry['Industry'] = customer_period_with_industry['Customer_Name'].map(customer_industry_map)

industry_results = []

for industry in industries:
    industry_data = customer_period_with_industry[customer_period_with_industry['Industry'] == industry]
    
    if len(industry_data) == 0:
        industry_results.append({
            'Industry': industry,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })
        continue
    
    # Filter active customers
    active_cols = ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']
    active_mask = (industry_data[active_cols] != 0).any(axis=1)
    active_industry_data = industry_data[active_mask]
    
    if len(active_industry_data) > 1:
        t_stat, p_value = stats.ttest_ind(active_industry_data['Change_2025'], 
                                          active_industry_data['Change_2024'], 
                                          equal_var=False)
        did_effect = active_industry_data['Change_2025'].mean() - active_industry_data['Change_2024'].mean()
    else:
        t_stat, p_value, did_effect = np.nan, np.nan, 0
        
    industry_results.append({
        'Industry': industry,
        'DiD_Effect_Mean': did_effect,
        'T_Statistic': t_stat,
        'P_Value': p_value,
        'Active_Customers': len(active_industry_data)
    })

ind_results_df = pd.DataFrame(industry_results)
print(f"Industry analysis completed in {time.time() - start_time:.2f} seconds")
print(ind_results_df.round(4))

print("\nIndustry Interpretations:")
for _, row in ind_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Industry']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Industry']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Industry']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

print("\n--- Analysis Complete ---")





#######
# --- 7. COMPREHENSIVE VISUALIZATIONS FOR PRESENTATION ---
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.figure_factory as ff

print("\n--- Creating Comprehensive Presentation Visualizations ---")

# === SLIDE 3: OVERALL ANALYSIS - 4 CHARTS ===
print("Creating Overall Analysis Dashboard...")

# Chart 3A: Time Series Comparison
daily_data = df_filtered.groupby(['Date', 'Period'])['Amount'].sum().reset_index()
daily_pivot = daily_data.pivot(index='Date', columns='Period', values='Amount').fillna(0)

fig_overall_time = go.Figure()
fig_overall_time.add_trace(go.Scatter(x=daily_pivot.index[daily_pivot['pre_2024'].notna()], y=daily_pivot['pre_2024'].dropna(), 
                                     mode='lines', name='2024 Pre', line=dict(color='lightblue', width=2)))
fig_overall_time.add_trace(go.Scatter(x=daily_pivot.index[daily_pivot['post_2024'].notna()], y=daily_pivot['post_2024'].dropna(), 
                                     mode='lines', name='2024 Post', line=dict(color='blue', width=2)))
fig_overall_time.add_trace(go.Scatter(x=daily_pivot.index[daily_pivot['pre_2025'].notna()], y=daily_pivot['pre_2025'].dropna(), 
                                     mode='lines', name='2025 Pre', line=dict(color='lightcoral', width=2)))
fig_overall_time.add_trace(go.Scatter(x=daily_pivot.index[daily_pivot['post_2025'].notna()], y=daily_pivot['post_2025'].dropna(), 
                                     mode='lines', name='2025 Post', line=dict(color='red', width=3)))
fig_overall_time.add_vline(x=tariff_date, line_dash="dash", line_color="black", annotation_text="Tariff", annotation_position="top")
fig_overall_time.update_layout(title="Daily Net Buy Trends", xaxis_title="Date", yaxis_title="Daily Net Buy ($)", 
                               template='plotly_white', height=300, showlegend=True)

# Chart 3B: Before/After Box Plots
box_data = pd.DataFrame({
    'Period': ['2024 Pre', '2024 Post', '2025 Pre', '2025 Post'],
    'Mean_NetBuy': [
        customer_period_pivot['pre_2024'].mean(),
        customer_period_pivot['post_2024'].mean(),
        customer_period_pivot['pre_2025'].mean(),
        customer_period_pivot['post_2025'].mean()
    ],
    'Values': [
        customer_period_pivot['pre_2024'].tolist(),
        customer_period_pivot['post_2024'].tolist(),
        customer_period_pivot['pre_2025'].tolist(),
        customer_period_pivot['post_2025'].tolist()
    ]
})

fig_overall_box = go.Figure()
colors = ['lightblue', 'blue', 'lightcoral', 'red']
for i, period in enumerate(['pre_2024', 'post_2024', 'pre_2025', 'post_2025']):
    fig_overall_box.add_trace(go.Box(y=customer_period_pivot[period], name=period.replace('_', ' ').title(), 
                                    marker_color=colors[i], boxmean=True))
fig_overall_box.update_layout(title="Customer Net Buy Distribution", yaxis_title="Net Buy ($)", 
                             template='plotly_white', height=300)

# Chart 3C: Change Distribution Histogram
fig_overall_hist = go.Figure()
fig_overall_hist.add_trace(go.Histogram(x=customer_period_pivot['Change_2024'], name='2024 Change', 
                                       opacity=0.7, marker_color='blue', nbinsx=30))
fig_overall_hist.add_trace(go.Histogram(x=customer_period_pivot['Change_2025'], name='2025 Change', 
                                       opacity=0.7, marker_color='red', nbinsx=30))
fig_overall_hist.update_layout(title="Distribution of Customer Changes", xaxis_title="Net Buy Change ($)", 
                              yaxis_title="Number of Customers", barmode='overlay', template='plotly_white', height=300)

# Chart 3D: Statistical Summary
fig_overall_stats = go.Figure(data=[go.Table(
    header=dict(values=['Metric', '2024 Change', '2025 Change', 'Difference', 'P-Value'],
                fill_color='lightblue', align='center', font_size=12),
    cells=dict(values=[
        ['Mean Change', 'Std Dev', 'Median', 'Active Customers'],
        [f"${customer_period_pivot['Change_2024'].mean():,.0f}", 
         f"${customer_period_pivot['Change_2024'].std():,.0f}",
         f"${customer_period_pivot['Change_2024'].median():,.0f}",
         f"{len(customer_period_pivot)}"],
        [f"${customer_period_pivot['Change_2025'].mean():,.0f}", 
         f"${customer_period_pivot['Change_2025'].std():,.0f}",
         f"${customer_period_pivot['Change_2025'].median():,.0f}",
         f"{len(customer_period_pivot)}"],
        [f"${customer_period_pivot['Change_2025'].mean() - customer_period_pivot['Change_2024'].mean():,.0f}",
         "N/A", "N/A", "Same"],
        ["0.5766", "N/A", "N/A", "Not Significant"]
    ], fill_color='white', align='center', font_size=10))
])
fig_overall_stats.update_layout(title="Statistical Summary", height=300, template='plotly_white')

# Show all overall charts
fig_overall_time.show()
fig_overall_box.show() 
fig_overall_hist.show()
fig_overall_stats.show()

# === SLIDE 4: SECURITY TYPE ANALYSIS - 4 CHARTS ===
print("Creating Security Type Analysis Dashboard...")

# Chart 4A: Impact Bar Chart (Significant Only)
sig_security = sec_results_df[sec_results_df['P_Value'] < 0.05].copy()
sig_security = sig_security.sort_values('DiD_Effect_Mean')
colors_sec = ['red' if x < 0 else 'green' for x in sig_security['DiD_Effect_Mean']]

fig_sec_impact = go.Figure(data=[go.Bar(x=sig_security['DiD_Effect_Mean'], y=sig_security['Security_Type'], 
                                       orientation='h', marker_color=colors_sec,
                                       text=[f"${x:,.0f}" for x in sig_security['DiD_Effect_Mean']], textposition='outside')])
fig_sec_impact.add_vline(x=0, line_dash="dot", line_color="gray")
fig_sec_impact.update_layout(title="Significant Security Type Impacts", xaxis_title="Net Buy Change ($)", 
                            template='plotly_white', height=350)

# Chart 4B: P-Values Significance Chart
fig_sec_pval = go.Figure()
all_sec = sec_results_df.sort_values('P_Value')
colors_pval = ['red' if x < 0.05 else 'gray' for x in all_sec['P_Value']]
fig_sec_pval.add_trace(go.Bar(x=all_sec['Security_Type'], y=all_sec['P_Value'], marker_color=colors_pval,
                             text=[f"{x:.3f}" for x in all_sec['P_Value']], textposition='outside'))
fig_sec_pval.add_hline(y=0.05, line_dash="dash", line_color="red", annotation_text="Significance Threshold")
fig_sec_pval.update_layout(title="Statistical Significance by Security Type", xaxis_title="Security Type", 
                          yaxis_title="P-Value", template='plotly_white', height=350)

# Chart 4C: Customer Activity Heatmap
sec_activity = agg_data.groupby(['Security_Type', 'Period'])['Customer_Name'].nunique().reset_index()
sec_activity_pivot = sec_activity.pivot(index='Security_Type', columns='Period', values='Customer_Name').fillna(0)
fig_sec_heatmap = go.Figure(data=go.Heatmap(z=sec_activity_pivot.values, x=sec_activity_pivot.columns, 
                                           y=sec_activity_pivot.index, colorscale='Blues', 
                                           text=sec_activity_pivot.values, texttemplate="%{text}", textfont={"size":10}))
fig_sec_heatmap.update_layout(title="Active Customers by Security Type & Period", height=350, template='plotly_white')

# Chart 4D: Volume vs Impact Scatter
fig_sec_scatter = go.Figure()
fig_sec_scatter.add_trace(go.Scatter(x=sec_results_df['Active_Customers'], y=sec_results_df['DiD_Effect_Mean'], 
                                    mode='markers+text', text=sec_results_df['Security_Type'],
                                    textposition="top center", marker=dict(size=10, color=sec_results_df['P_Value'], 
                                    colorscale='RdYlBu_r', showscale=True, colorbar=dict(title="P-Value"))))
fig_sec_scatter.add_hline(y=0, line_dash="dot", line_color="gray")
fig_sec_scatter.update_layout(title="Impact vs Customer Activity", xaxis_title="Active Customers", 
                             yaxis_title="DiD Effect ($)", template='plotly_white', height=350)

fig_sec_impact.show()
fig_sec_pval.show()
fig_sec_heatmap.show()
fig_sec_scatter.show()

# === SLIDE 5: INDUSTRY ANALYSIS - 4 CHARTS ===
print("Creating Industry Analysis Dashboard...")

# Chart 5A: Industry Impact Bar Chart
sig_industry = ind_results_df[ind_results_df['P_Value'] < 0.05].copy()
sig_industry = sig_industry.sort_values('DiD_Effect_Mean')
colors_ind = ['red' if x < 0 else 'green' for x in sig_industry['DiD_Effect_Mean']]

fig_ind_impact = go.Figure(data=[go.Bar(x=sig_industry['DiD_Effect_Mean'], y=sig_industry['Industry'], 
                                       orientation='h', marker_color=colors_ind,
                                       text=[f"${x:,.0f}" for x in sig_industry['DiD_Effect_Mean']], textposition='outside')])
fig_ind_impact.add_vline(x=0, line_dash="dot", line_color="gray")
fig_ind_impact.update_layout(title="Significant Industry Impacts", xaxis_title="Net Buy Change ($)", 
                            template='plotly_white', height=350)

# Chart 5B: Industry Customer Distribution
ind_customers = df.groupby('Customer_Industry')['Customer_Name'].nunique().reset_index()
ind_customers = ind_customers.sort_values('Customer_Name', ascending=False)
fig_ind_customers = go.Figure(data=[go.Bar(x=ind_customers['Customer_Industry'], y=ind_customers['Customer_Name'],
                                          marker_color='steelblue')])
fig_ind_customers.update_layout(title="Customer Base by Industry", xaxis_title="Industry", 
                               yaxis_title="Number of Customers", template='plotly_white', height=350,
                               xaxis_tickangle=-45)

# Chart 5C: Industry Trading Volume Comparison
ind_volume = df_filtered.groupby(['Customer_Industry', 'Period'])['Amount'].sum().reset_index()
ind_volume_pivot = ind_volume.pivot(index='Customer_Industry', columns='Period', values='Amount').fillna(0)
fig_ind_volume = go.Figure()
for period in ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']:
    fig_ind_volume.add_trace(go.Bar(name=period.replace('_', ' ').title(), x=ind_volume_pivot.index, 
                                   y=ind_volume_pivot[period]))
fig_ind_volume.update_layout(title="Trading Volume by Industry & Period", xaxis_title="Industry", 
                            yaxis_title="Total Net Buy ($)", barmode='group', template='plotly_white', 
                            height=350, xaxis_tickangle=-45)

# Chart 5D: Risk Assessment Matrix
risk_data = ind_results_df.copy()
risk_data['Risk_Level'] = pd.cut(risk_data['P_Value'], bins=[0, 0.01, 0.05, 1], 
                                labels=['High Impact', 'Moderate Impact', 'No Impact'])
risk_data['Effect_Direction'] = ['Negative' if x < 0 else 'Positive' if x > 0 else 'Neutral' 
                                for x in risk_data['DiD_Effect_Mean']]

fig_ind_risk = go.Figure(data=[go.Table(
    header=dict(values=['Industry', 'Impact ($)', 'Risk Level', 'Direction', 'Active Customers'],
                fill_color='lightblue', align='center', font_size=11),
    cells=dict(values=[
        risk_data['Industry'],
        [f"${x:,.0f}" for x in risk_data['DiD_Effect_Mean']],
        risk_data['Risk_Level'],
        risk_data['Effect_Direction'],
        risk_data['Active_Customers']
    ], fill_color='white', align='center', font_size=10))
])
fig_ind_risk.update_layout(title="Industry Risk Assessment Matrix", height=400, template='plotly_white')

fig_ind_impact.show()
fig_ind_customers.show()
fig_ind_volume.show()
fig_ind_risk.show()

# === BONUS: EXECUTIVE SUMMARY DASHBOARD ===
print("Creating Executive Summary Dashboard...")

# Create a comprehensive summary
summary_metrics = {
    'Total Customers Analyzed': len(customer_period_pivot),
    'Total Trades': len(df),
    'Significant Security Types': len(sig_security),
    'Significant Industries': len(sig_industry),
    'Overall P-Value': 0.5766,
    'Analysis Period': '30 days pre/post tariff'
}

fig_summary = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Key Metrics', 'Security Impact', 'Industry Impact', 'Customer Activity'),
    specs=[[{"type": "table"}, {"type": "bar"}],
           [{"type": "bar"}, {"type": "scatter"}]]
)

# Add summary table
fig_summary.add_trace(go.Table(
    header=dict(values=['Metric', 'Value'], fill_color='lightblue'),
    cells=dict(values=[list(summary_metrics.keys()), list(summary_metrics.values())], 
               fill_color='white')
), row=1, col=1)

# Add security summary
fig_summary.add_trace(go.Bar(x=sig_security['Security_Type'], y=sig_security['DiD_Effect_Mean'], 
                            marker_color=colors_sec, name="Security Impact"), row=1, col=2)

# Add industry summary  
fig_summary.add_trace(go.Bar(x=sig_industry['Industry'], y=sig_industry['DiD_Effect_Mean'],
                            marker_color=colors_ind, name="Industry Impact"), row=2, col=1)

# Add customer changes scatter
fig_summary.add_trace(go.Scatter(x=customer_period_pivot['Change_2024'], y=customer_period_pivot['Change_2025'],
                                mode='markers', opacity=0.6, name="Customer Changes"), row=2, col=2)

fig_summary.update_layout(height=600, showlegend=False, title_text="Executive Summary Dashboard")
fig_summary.show()

print("\n--- All Visualizations Created Successfully! ---")
print("You now have 12+ charts across 4 comprehensive dashboards:")
print("- Overall Analysis: 4 charts (time series, distributions, stats)")
print("- Security Types: 4 charts (impact, significance, activity, correlation)")  
print("- Industries: 4 charts (impact, customer base, volume, risk matrix)")
print("- Executive Summary: 1 comprehensive dashboard")
print("\nThis will definitely impress your manager! 🚀")
