
# --- 2. Define Time Periods ---
print("--- Defining Time Periods ---")
tariff_date = pd.Timestamp('2025-04-02')
pre_days = 30
post_days = 30

all_business_days = pd.date_range(start='2023-01-01', end='2025-05-29', freq='B')
tariff_idx = all_business_days.get_loc(tariff_date)

pre_2025_start_idx = max(0, tariff_idx - pre_days)
pre_2025_start_date = all_business_days[pre_2025_start_idx]
pre_2025_end_date = tariff_date - pd.Timedelta(days=1)

post_2025_end_idx = min(len(all_business_days) - 1, tariff_idx + post_days - 1)
post_2025_end_date = all_business_days[post_2025_end_idx]
post_2025_start_date = tariff_date

pre_2024_start_date = pre_2025_start_date - pd.DateOffset(years=1)
pre_2024_end_date = pre_2025_end_date - pd.DateOffset(years=1)
post_2024_start_date = post_2025_start_date - pd.DateOffset(years=1)
post_2024_end_date = post_2025_end_date - pd.DateOffset(years=1)

periods = {
    'pre_2025': (pre_2025_start_date, pre_2025_end_date),
    'post_2025': (post_2025_start_date, post_2025_end_date),
    'pre_2024': (pre_2024_start_date, pre_2024_end_date),
    'post_2024': (post_2024_start_date, post_2024_end_date),
}

for name, (start, end) in periods.items():
    print(f"{name.replace('_', ' ').title()}: {start.date()} to {end.date()}")

# --- 3. OPTIMIZED: Single Aggregation for All Analyses ---
print("\n--- Optimized Aggregation for All Analyses ---")
start_time = time.time()

# Create period indicators for efficient filtering
def assign_period(date):
    for period_name, (start_date, end_date) in periods.items():
        if start_date <= date <= end_date:
            return period_name
    return None

# Filter data to only relevant periods first
df_filtered = df[df['Date'].apply(assign_period).notna()].copy()
df_filtered['Period'] = df_filtered['Date'].apply(assign_period)

print(f"Filtered data from {len(df)} to {len(df_filtered)} rows for analysis periods")

# Single comprehensive aggregation
# Group by Customer, Period, Security_Type, and Industry to get all combinations at once
agg_data = df_filtered.groupby([
    'Customer_Name', 'Customer_Industry', 'Period', 'Security_Type'
])['Amount'].sum().reset_index()

print(f"Aggregation completed in {time.time() - start_time:.2f} seconds")

# --- 4. Overall Net Buy Analysis (Same as before) ---
print("\n--- 4. Overall Net Buy Analysis ---")

# Pivot to get customer-period level data
customer_period = df_filtered.groupby(['Customer_Name', 'Period'])['Amount'].sum().reset_index()
customer_period_pivot = customer_period.pivot(index='Customer_Name', columns='Period', values='Amount').fillna(0)

# Calculate changes
customer_period_pivot['Change_2025'] = customer_period_pivot['post_2025'] - customer_period_pivot['pre_2025']
customer_period_pivot['Change_2024'] = customer_period_pivot['post_2024'] - customer_period_pivot['pre_2024']

# Statistical tests
t_stat, p_value = stats.ttest_ind(customer_period_pivot['Change_2025'], 
                                  customer_period_pivot['Change_2024'], 
                                  equal_var=False)

# Descriptive statistics for intuitive interpretation
avg_pre_2025 = customer_period_pivot['pre_2025'].mean()
avg_post_2025 = customer_period_pivot['post_2025'].mean()
avg_change_2025 = customer_period_pivot['Change_2025'].mean()
avg_change_2024 = customer_period_pivot['Change_2024'].mean()

print("=== OVERALL NET BUY SUMMARY ===")
print(f"2025 Before Tariff (Average): ${avg_pre_2025:,.0f}")
print(f"2025 After Tariff (Average): ${avg_post_2025:,.0f}")
print(f"2025 Change (After - Before): ${avg_change_2025:,.0f}")
print(f"2024 Change (Same Period): ${avg_change_2024:,.0f}")
print(f"DiD Effect (2025 Change - 2024 Change): ${avg_change_2025 - avg_change_2024:,.2f}")
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Conclusion: Significant change in net buy post-tariff beyond seasonal trends.")
else:
    print("Conclusion: No significant difference beyond normal seasonality.")

# --- 5. OPTIMIZED Security Type Analysis ---
print("\n--- 5. Optimized Security Type Analysis ---")
start_time = time.time()

# Pivot aggregated data to get customer-period-security level
sec_pivot = agg_data.pivot_table(
    index=['Customer_Name'], 
    columns=['Period', 'Security_Type'], 
    values='Amount', 
    fill_value=0
)

# Get all unique customers for consistent indexing
all_customers = customer_period_pivot.index

security_type_results = []

for sec_type in security_types:
    try:
        # Create DataFrame with proper index from all customers
        sec_data_dict = {}
        
        for period in ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']:
            if ('Period' in sec_pivot.columns.names and 'Security_Type' in sec_pivot.columns.names and 
                (period, sec_type) in sec_pivot.columns):
                sec_data_dict[period] = sec_pivot[(period, sec_type)]
            else:
                # Create a Series with zeros for all customers
                sec_data_dict[period] = pd.Series(0, index=all_customers)
        
        sec_data = pd.DataFrame(sec_data_dict)
        
        sec_data['Change_2025'] = sec_data['post_2025'] - sec_data['pre_2025']
        sec_data['Change_2024'] = sec_data['post_2024'] - sec_data['pre_2024']
        
        # Filter active customers for this security type
        active_mask = (sec_data[['pre_2024', 'post_2024', 'pre_2025', 'post_2025']] != 0).any(axis=1)
        active_sec_data = sec_data[active_mask]
        
        # Calculate descriptive statistics for interpretation
        avg_pre_2025_sec = active_sec_data['pre_2025'].mean()
        avg_post_2025_sec = active_sec_data['post_2025'].mean()
        avg_change_2025_sec = active_sec_data['Change_2025'].mean()
        avg_change_2024_sec = active_sec_data['Change_2024'].mean()
        
        if len(active_sec_data) > 1:
            t_stat, p_value = stats.ttest_ind(active_sec_data['Change_2025'], 
                                              active_sec_data['Change_2024'], 
                                              equal_var=False)
            did_effect = avg_change_2025_sec - avg_change_2024_sec
        else:
            t_stat, p_value, did_effect = np.nan, np.nan, 0
            
        security_type_results.append({
            'Security_Type': sec_type,
            'Pre_2025_Avg': avg_pre_2025_sec,
            'Post_2025_Avg': avg_post_2025_sec,
            'Change_2025_Avg': avg_change_2025_sec,
            'Change_2024_Avg': avg_change_2024_sec,
            'DiD_Effect_Mean': did_effect,
            'T_Statistic': t_stat,
            'P_Value': p_value,
            'Active_Customers': len(active_sec_data)
        })
        
    except Exception as e:
        print(f"Error processing {sec_type}: {e}")
        security_type_results.append({
            'Security_Type': sec_type,
            'Pre_2025_Avg': 0,
            'Post_2025_Avg': 0,
            'Change_2025_Avg': 0,
            'Change_2024_Avg': 0,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })

print("\n=== SECURITY TYPE DETAILED RESULTS ===")
sec_results_df = pd.DataFrame(security_type_results)
print(sec_results_df[['Security_Type', 'Pre_2025_Avg', 'Post_2025_Avg', 'Change_2025_Avg', 'DiD_Effect_Mean', 'P_Value', 'Active_Customers']].round(0))

print("\nSecurity Type Interpretations:")
for _, row in sec_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        direction = "increased" if row['Change_2025_Avg'] > 0 else "decreased"
        print(f"  - {row['Security_Type']}: SIGNIFICANT IMPACT")
        print(f"    • Before Tariff: ${row['Pre_2025_Avg']:,.0f} | After Tariff: ${row['Post_2025_Avg']:,.0f}")
        print(f"    • Net buy {direction} by ${abs(row['Change_2025_Avg']):,.0f} (DiD: ${row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Security_Type']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Security_Type']}: No significant impact (p={row['P_Value']:.4f})")

# --- 6. OPTIMIZED Industry Analysis ---
print("\n--- 6. Optimized Industry Analysis ---")
start_time = time.time()

# Get customer-industry mapping - handle potential duplicates
customer_industry_df = df[['Customer_Name', 'Customer_Industry']].drop_duplicates()

# Check for customers with multiple industries (data quality issue)
customer_counts = customer_industry_df['Customer_Name'].value_counts()
if (customer_counts > 1).any():
    print(f"Warning: {(customer_counts > 1).sum()} customers have multiple industries. Using first occurrence.")
    # Keep only the first occurrence for each customer
    customer_industry_df = customer_industry_df.drop_duplicates(subset=['Customer_Name'], keep='first')

customer_industry_map = customer_industry_df.set_index('Customer_Name')['Customer_Industry']

# Add industry info to customer_period_pivot
customer_period_with_industry = customer_period_pivot.copy()
customer_period_with_industry = customer_period_with_industry.reset_index()  # Reset index to make Customer_Name a column
customer_period_with_industry['Industry'] = customer_period_with_industry['Customer_Name'].map(customer_industry_map)

industry_results = []

for industry in industries:
    industry_data = customer_period_with_industry[customer_period_with_industry['Industry'] == industry]
    
    if len(industry_data) == 0:
        industry_results.append({
            'Industry': industry,
            'Pre_2025_Avg': 0,
            'Post_2025_Avg': 0,
            'Change_2025_Avg': 0,
            'Change_2024_Avg': 0,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })
        continue
    
    # Filter active customers
    active_cols = ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']
    active_mask = (industry_data[active_cols] != 0).any(axis=1)
    active_industry_data = industry_data[active_mask]
    
    # Calculate descriptive statistics
    avg_pre_2025_ind = active_industry_data['pre_2025'].mean() if len(active_industry_data) > 0 else 0
    avg_post_2025_ind = active_industry_data['post_2025'].mean() if len(active_industry_data) > 0 else 0
    avg_change_2025_ind = active_industry_data['Change_2025'].mean() if len(active_industry_data) > 0 else 0
    avg_change_2024_ind = active_industry_data['Change_2024'].mean() if len(active_industry_data) > 0 else 0
    
    if len(active_industry_data) > 1:
        t_stat, p_value = stats.ttest_ind(active_industry_data['Change_2025'], 
                                          active_industry_data['Change_2024'], 
                                          equal_var=False)
        did_effect = avg_change_2025_ind - avg_change_2024_ind
    else:
        t_stat, p_value, did_effect = np.nan, np.nan, 0
        
    industry_results.append({
        'Industry': industry,
        'Pre_2025_Avg': avg_pre_2025_ind,
        'Post_2025_Avg': avg_post_2025_ind,
        'Change_2025_Avg': avg_change_2025_ind,
        'Change_2024_Avg': avg_change_2024_ind,
        'DiD_Effect_Mean': did_effect,
        'T_Statistic': t_stat,
        'P_Value': p_value,
        'Active_Customers': len(active_industry_data)
    })

ind_results_df = pd.DataFrame(industry_results)
print(f"Industry analysis completed in {time.time() - start_time:.2f} seconds")
print(ind_results_df.round(4))

print("\nIndustry Interpretations:")
for _, row in ind_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Industry']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Industry']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Industry']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

print("\n--- Analysis Complete ---")




#### NEW
import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.formula.api as smf
import time

# --- 1. Regenerate Dummy Data (Your provided code) ---
# Generate date ranges
start_date = '2023-01-01'
end_date = '2025-05-29'
dates = pd.date_range(start=start_date, end=end_date, freq='B')  # Business days only

# Key events
tariff_date = pd.Timestamp('2025-04-02')

# Customer and security setup
n_customers = 500
customers = [f'Customer_{i:03d}' for i in range(n_customers)]
industries = ['Technology', 'Manufacturing', 'Finance', 'Retail', 'Healthcare',
              'Energy', 'Real Estate', 'Consumer Goods']
security_types = ['Foreign Stocks', 'Local Stocks', 'Bonds', 'Certificate of Deposit',
                  'Unit Trusts', 'ETFs']

# Generate trades
trades = []
for date in dates:
    # Adjust trading patterns based on events
    if date >= tariff_date:
        foreign_bias = 0.25
        volume_multiplier = 1.3
        bond_bias = 0.2
    elif date >= pd.Timestamp('2025-01-01'):
        foreign_bias = 0.45
        volume_multiplier = 1.1
        bond_bias = 0.1
    else:
        foreign_bias = 0.5
        volume_multiplier = 1.0
        bond_bias = 0.05

    n_trades = np.random.poisson(200 * volume_multiplier)

    for _ in range(n_trades):
        customer = np.random.choice(customers)
        industry = np.random.choice(industries)

        security_probs = {
            'Foreign Stocks': foreign_bias,
            'Local Stocks': 0.4 - (foreign_bias - 0.25),
            'Bonds': bond_bias,
            'Certificate of Deposit': 0.05,
            'Unit Trusts': 0.03,
            'ETFs': 0.02
        }
        sum_probs = sum(security_probs.values())
        security_probs = {k: v / sum_probs for k, v in security_probs.items()}

        security_type = np.random.choice(list(security_probs.keys()), p=list(security_probs.values()))

        if np.random.rand() < 0.55:
            investment_amount = np.random.lognormal(10, 1.5) * 1000
        else:
            investment_amount = -(np.random.lognormal(10, 1.5) * 1000)

        trades.append({
            'Date': date,
            'Customer_Name': customer,
            'Customer_Industry': industry,
            'Amount': investment_amount,
            'Security_Type': security_type
        })

df = pd.DataFrame(trades)
df['Date'] = pd.to_datetime(df['Date'])
print(f"Total trades generated: {len(df)}")
print(f"Data range: {df['Date'].min().date()} to {df['Date'].max().date()}\n")

# --- 2. Define Time Periods ---
print("--- Defining Time Periods ---")
tariff_date = pd.Timestamp('2025-04-02')
pre_days = 30
post_days = 30

all_business_days = pd.date_range(start='2023-01-01', end='2025-05-29', freq='B')
tariff_idx = all_business_days.get_loc(tariff_date)

pre_2025_start_idx = max(0, tariff_idx - pre_days)
pre_2025_start_date = all_business_days[pre_2025_start_idx]
pre_2025_end_date = tariff_date - pd.Timedelta(days=1)

post_2025_end_idx = min(len(all_business_days) - 1, tariff_idx + post_days - 1)
post_2025_end_date = all_business_days[post_2025_end_idx]
post_2025_start_date = tariff_date

pre_2024_start_date = pre_2025_start_date - pd.DateOffset(years=1)
pre_2024_end_date = pre_2025_end_date - pd.DateOffset(years=1)
post_2024_start_date = post_2025_start_date - pd.DateOffset(years=1)
post_2024_end_date = post_2025_end_date - pd.DateOffset(years=1)

periods = {
    'pre_2025': (pre_2025_start_date, pre_2025_end_date),
    'post_2025': (post_2025_start_date, post_2025_end_date),
    'pre_2024': (pre_2024_start_date, pre_2024_end_date),
    'post_2024': (post_2024_start_date, post_2024_end_date),
}

for name, (start, end) in periods.items():
    print(f"{name.replace('_', ' ').title()}: {start.date()} to {end.date()}")

# --- 3. OPTIMIZED: Single Aggregation for All Analyses ---
print("\n--- Optimized Aggregation for All Analyses ---")
start_time = time.time()

# Create period indicators for efficient filtering
def assign_period(date):
    for period_name, (start_date, end_date) in periods.items():
        if start_date <= date <= end_date:
            return period_name
    return None

# Filter data to only relevant periods first
df_filtered = df[df['Date'].apply(assign_period).notna()].copy()
df_filtered['Period'] = df_filtered['Date'].apply(assign_period)

print(f"Filtered data from {len(df)} to {len(df_filtered)} rows for analysis periods")

# Single comprehensive aggregation
# Group by Customer, Period, Security_Type, and Industry to get all combinations at once
agg_data = df_filtered.groupby([
    'Customer_Name', 'Customer_Industry', 'Period', 'Security_Type'
])['Amount'].sum().reset_index()

print(f"Aggregation completed in {time.time() - start_time:.2f} seconds")

# --- 4. Overall Net Buy Analysis (Same as before) ---
print("\n--- 4. Overall Net Buy Analysis ---")

# Pivot to get customer-period level data
customer_period = df_filtered.groupby(['Customer_Name', 'Period'])['Amount'].sum().reset_index()
customer_period_pivot = customer_period.pivot(index='Customer_Name', columns='Period', values='Amount').fillna(0)

# Calculate changes
customer_period_pivot['Change_2025'] = customer_period_pivot['post_2025'] - customer_period_pivot['pre_2025']
customer_period_pivot['Change_2024'] = customer_period_pivot['post_2024'] - customer_period_pivot['pre_2024']

# Statistical tests
t_stat, p_value = stats.ttest_ind(customer_period_pivot['Change_2025'], 
                                  customer_period_pivot['Change_2024'], 
                                  equal_var=False)

print(f"DiD (2025 Change - 2024 Change) - Mean difference: {customer_period_pivot['Change_2025'].mean() - customer_period_pivot['Change_2024'].mean():,.2f}")
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Conclusion: Significant change in net buy post-tariff beyond seasonal trends.")
else:
    print("Conclusion: No significant difference beyond normal seasonality.")

# --- 5. OPTIMIZED Security Type Analysis ---
print("\n--- 5. Optimized Security Type Analysis ---")
start_time = time.time()

# Pivot aggregated data to get customer-period-security level
sec_pivot = agg_data.pivot_table(
    index=['Customer_Name'], 
    columns=['Period', 'Security_Type'], 
    values='Amount', 
    fill_value=0
)

security_type_results = []

for sec_type in security_types:
    try:
        # Extract data for this security type
        sec_data = pd.DataFrame({
            'pre_2024': sec_pivot[('pre_2024', sec_type)] if ('pre_2024', sec_type) in sec_pivot.columns else 0,
            'post_2024': sec_pivot[('post_2024', sec_type)] if ('post_2024', sec_type) in sec_pivot.columns else 0,
            'pre_2025': sec_pivot[('pre_2025', sec_type)] if ('pre_2025', sec_type) in sec_pivot.columns else 0,
            'post_2025': sec_pivot[('post_2025', sec_type)] if ('post_2025', sec_type) in sec_pivot.columns else 0,
        })
        
        sec_data['Change_2025'] = sec_data['post_2025'] - sec_data['pre_2025']
        sec_data['Change_2024'] = sec_data['post_2024'] - sec_data['pre_2024']
        
        # Filter active customers for this security type
        active_mask = (sec_data[['pre_2024', 'post_2024', 'pre_2025', 'post_2025']] != 0).any(axis=1)
        active_sec_data = sec_data[active_mask]
        
        if len(active_sec_data) > 1:
            t_stat, p_value = stats.ttest_ind(active_sec_data['Change_2025'], 
                                              active_sec_data['Change_2024'], 
                                              equal_var=False)
            did_effect = active_sec_data['Change_2025'].mean() - active_sec_data['Change_2024'].mean()
        else:
            t_stat, p_value, did_effect = np.nan, np.nan, 0
            
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': did_effect,
            'T_Statistic': t_stat,
            'P_Value': p_value,
            'Active_Customers': len(active_sec_data)
        })
        
    except Exception as e:
        print(f"Error processing {sec_type}: {e}")
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })

sec_results_df = pd.DataFrame(security_type_results)
print(f"Security type analysis completed in {time.time() - start_time:.2f} seconds")
print(sec_results_df.round(4))

print("\nSecurity Type Interpretations:")
for _, row in sec_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Security_Type']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Security_Type']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Security_Type']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")




# --- 6. OPTIMIZED Industry Analysis ---
print("\n--- 6. Optimized Industry Analysis ---")
start_time = time.time()

# Get customer-industry mapping - handle potential duplicates
customer_industry_df = df[['Customer_Name', 'Customer_Industry']].drop_duplicates()

# Check for customers with multiple industries (data quality issue)
customer_counts = customer_industry_df['Customer_Name'].value_counts()
if (customer_counts > 1).any():
    print(f"Warning: {(customer_counts > 1).sum()} customers have multiple industries. Using first occurrence.")
    # Keep only the first occurrence for each customer
    customer_industry_df = customer_industry_df.drop_duplicates(subset=['Customer_Name'], keep='first')

customer_industry_map = customer_industry_df.set_index('Customer_Name')['Customer_Industry']

# Add industry info to customer_period_pivot
customer_period_with_industry = customer_period_pivot.copy()
customer_period_with_industry = customer_period_with_industry.reset_index()  # Reset index to make Customer_Name a column
customer_period_with_industry['Industry'] = customer_period_with_industry['Customer_Name'].map(customer_industry_map)

industry_results = []

for industry in industries:
    industry_data = customer_period_with_industry[customer_period_with_industry['Industry'] == industry]
    
    if len(industry_data) == 0:
        industry_results.append({
            'Industry': industry,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })
        continue
    
    # Filter active customers
    active_cols = ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']
    active_mask = (industry_data[active_cols] != 0).any(axis=1)
    active_industry_data = industry_data[active_mask]
    
    if len(active_industry_data) > 1:
        t_stat, p_value = stats.ttest_ind(active_industry_data['Change_2025'], 
                                          active_industry_data['Change_2024'], 
                                          equal_var=False)
        did_effect = active_industry_data['Change_2025'].mean() - active_industry_data['Change_2024'].mean()
    else:
        t_stat, p_value, did_effect = np.nan, np.nan, 0
        
    industry_results.append({
        'Industry': industry,
        'DiD_Effect_Mean': did_effect,
        'T_Statistic': t_stat,
        'P_Value': p_value,
        'Active_Customers': len(active_industry_data)
    })

ind_results_df = pd.DataFrame(industry_results)
print(f"Industry analysis completed in {time.time() - start_time:.2f} seconds")
print(ind_results_df.round(4))

print("\nIndustry Interpretations:")
for _, row in ind_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Industry']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Industry']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Industry']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

print("\n--- Analysis Complete ---")



# --- 7. VISUALIZATION FOR PPT (PLOTLY) ---
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

# Set professional color palette
colors = {
    'before': '#3498db',  # Blue
    'after': '#e74c3c',   # Red
    'positive': '#27ae60', # Green
    'negative': '#e74c3c', # Red
    'background': '#f8f9fa',
    'text': '#2c3e50'
}

# --- Security Type Visualizations ---
print("\n--- Creating Security Type Visualizations (Plotly) ---")

# Filter significant security types and top 7 by absolute change
sec_significant = sec_results_df[
    (pd.notna(sec_results_df['P_Value'])) & 
    (sec_results_df['P_Value'] < 0.05) & 
    (sec_results_df['Active_Customers'] >= 2)
].copy()

if len(sec_significant) > 0:
    # Add percentage change calculation
    sec_significant['Pct_Change'] = ((sec_significant['Post_2025_Avg'] - sec_significant['Pre_2025_Avg']) / 
                                   sec_significant['Pre_2025_Avg'].abs() * 100)
    sec_significant['Abs_Change'] = sec_significant['Post_2025_Avg'] - sec_significant['Pre_2025_Avg']
    
    # Select top 7 by absolute change magnitude
    sec_significant['Abs_Change_Magnitude'] = sec_significant['Abs_Change'].abs()
    sec_plot_data = sec_significant.nlargest(7, 'Abs_Change_Magnitude')
    
    # Create subplots
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Net Buy: Before vs After Tariff', 'Difference-in-Differences Impact'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # Chart 1: Before vs After
    fig.add_trace(
        go.Bar(
            name='Before Tariff',
            x=sec_plot_data['Security_Type'],
            y=sec_plot_data['Pre_2025_Avg']/1000,
            marker_color=colors['before'],
            opacity=0.8,
            text=[f'${val/1000:,.0f}K' for val in sec_plot_data['Pre_2025_Avg']],
            textposition='outside',
            hovertemplate='<b>%{x}</b><br>Before: $%{y:,.0f}K<extra></extra>'
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Bar(
            name='After Tariff',
            x=sec_plot_data['Security_Type'],
            y=sec_plot_data['Post_2025_Avg']/1000,
            marker_color=colors['after'],
            opacity=0.8,
            text=[f'${val/1000:,.0f}K' for val in sec_plot_data['Post_2025_Avg']],
            textposition='outside',
            hovertemplate='<b>%{x}</b><br>After: $%{y:,.0f}K<extra></extra>'
        ),
        row=1, col=1
    )
    
    # Add percentage change annotations
    for i, (idx, row) in enumerate(sec_plot_data.iterrows()):
        pct_change = row['Pct_Change']
        color = colors['positive'] if pct_change > 0 else colors['negative']
        y_pos = max(row['Pre_2025_Avg'], row['Post_2025_Avg'])/1000 * 1.15
        
        fig.add_annotation(
            x=row['Security_Type'],
            y=y_pos,
            text=f'<b>{pct_change:+.1f}%</b>',
            showarrow=False,
            font=dict(color=color, size=12),
            row=1, col=1
        )
    
    # Chart 2: DiD Effects
    bar_colors = [colors['positive'] if x > 0 else colors['negative'] for x in sec_plot_data['DiD_Effect_Mean']]
    
    fig.add_trace(
        go.Bar(
            name='DiD Effect',
            x=sec_plot_data['Security_Type'],
            y=sec_plot_data['DiD_Effect_Mean']/1000,
            marker_color=bar_colors,
            opacity=0.8,
            text=[f'${val/1000:,.0f}K' for val in sec_plot_data['DiD_Effect_Mean']],
            textposition='outside',
            hovertemplate='<b>%{x}</b><br>DiD Effect: $%{y:,.0f}K<br>P-value: %{customdata:.4f}<extra></extra>',
            customdata=sec_plot_data['P_Value'],
            showlegend=False
        ),
        row=1, col=2
    )
    
    # Add significance stars
    for i, (idx, row) in enumerate(sec_plot_data.iterrows()):
        if row['P_Value'] < 0.001:
            marker = '***'
        elif row['P_Value'] < 0.01:
            marker = '**'
        elif row['P_Value'] < 0.05:
            marker = '*'
        else:
            marker = ''
        
        if marker:
            y_pos = row['DiD_Effect_Mean']/1000
            y_offset = abs(y_pos) * 0.1 + 50
            y_annotation = y_pos + y_offset if y_pos >= 0 else y_pos - y_offset
            
            fig.add_annotation(
                x=row['Security_Type'],
                y=y_annotation,
                text=f'<b>{marker}</b>',
                showarrow=False,
                font=dict(color='black', size=16),
                row=1, col=2
            )
    
    # Add horizontal line at zero for DiD chart
    fig.add_hline(y=0, line_dash="solid", line_color="black", line_width=1, row=1, col=2)
    
    # Update layout
    fig.update_layout(
        title=dict(
            text='<b>Tariff Impact Analysis: Security Types</b>',
            x=0.5,
            font=dict(size=20, color=colors['text'])
        ),
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=-0.2,
            xanchor="center",
            x=0.25
        ),
        plot_bgcolor='white',
        paper_bgcolor='white',
        font=dict(size=12, color=colors['text']),
        height=600,
        width=1400
    )
    
    # Update axes
    fig.update_xaxes(title_text="Security Type", row=1, col=1, tickangle=45)
    fig.update_xaxes(title_text="Security Type", row=1, col=2, tickangle=45)
    fig.update_yaxes(title_text="Net Buy (Thousands $)", row=1, col=1)
    fig.update_yaxes(title_text="DiD Effect (Thousands $)", row=1, col=2)
    
    # Save as high-quality image
    fig.write_image("security_type_analysis.png", width=1400, height=600, scale=2)
    fig.show()

else:
    print("No significant security type changes found for visualization")

# --- Industry Visualizations ---
print("\n--- Creating Industry Visualizations (Plotly) ---")

# Filter significant industries and top 7 by absolute change
ind_significant = ind_results_df[
    (pd.notna(ind_results_df['P_Value'])) & 
    (ind_results_df['P_Value'] < 0.05) & 
    (ind_results_df['Active_Customers'] >= 2)
].copy()

if len(ind_significant) > 0:
    # Add percentage change calculation
    ind_significant['Pct_Change'] = ((ind_significant['Post_2025_Avg'] - ind_significant['Pre_2025_Avg']) / 
                                   ind_significant['Pre_2025_Avg'].abs() * 100)
    ind_significant['Abs_Change'] = ind_significant['Post_2025_Avg'] - ind_significant['Pre_2025_Avg']
    
    # Select top 7 by absolute change magnitude
    ind_significant['Abs_Change_Magnitude'] = ind_significant['Abs_Change'].abs()
    ind_plot_data = ind_significant.nlargest(7, 'Abs_Change_Magnitude')
    
    # Truncate long industry names
    ind_plot_data['Industry_Short'] = [name[:25] + '...' if len(name) > 25 else name for name in ind_plot_data['Industry']]
    
    # Create subplots
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Net Buy: Before vs After Tariff', 'Difference-in-Differences Impact'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # Chart 1: Before vs After
    fig.add_trace(
        go.Bar(
            name='Before Tariff',
            x=ind_plot_data['Industry_Short'],
            y=ind_plot_data['Pre_2025_Avg']/1000,
            marker_color='#2ecc71',  # Green
            opacity=0.8,
            text=[f'${val/1000:,.0f}K' for val in ind_plot_data['Pre_2025_Avg']],
            textposition='outside',
            hovertemplate='<b>%{x}</b><br>Before: $%{y:,.0f}K<extra></extra>'
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Bar(
            name='After Tariff',
            x=ind_plot_data['Industry_Short'],
            y=ind_plot_data['Post_2025_Avg']/1000,
            marker_color='#f39c12',  # Orange
            opacity=0.8,
            text=[f'${val/1000:,.0f}K' for val in ind_plot_data['Post_2025_Avg']],
            textposition='outside',
            hovertemplate='<b>%{x}</b><br>After: $%{y:,.0f}K<extra></extra>'
        ),
        row=1, col=1
    )
    
    # Add percentage change annotations
    for i, (idx, row) in enumerate(ind_plot_data.iterrows()):
        pct_change = row['Pct_Change']
        color = colors['positive'] if pct_change > 0 else colors['negative']
        y_pos = max(row['Pre_2025_Avg'], row['Post_2025_Avg'])/1000 * 1.15
        
        fig.add_annotation(
            x=row['Industry_Short'],
            y=y_pos,
            text=f'<b>{pct_change:+.1f}%</b>',
            showarrow=False,
            font=dict(color=color, size=12),
            row=1, col=1
        )
    
    # Chart 2: DiD Effects
    bar_colors = [colors['positive'] if x > 0 else colors['negative'] for x in ind_plot_data['DiD_Effect_Mean']]
    
    fig.add_trace(
        go.Bar(
            name='DiD Effect',
            x=ind_plot_data['Industry_Short'],
            y=ind_plot_data['DiD_Effect_Mean']/1000,
            marker_color=bar_colors,
            opacity=0.8,
            text=[f'${val/1000:,.0f}K' for val in ind_plot_data['DiD_Effect_Mean']],
            textposition='outside',
            hovertemplate='<b>%{x}</b><br>DiD Effect: $%{y:,.0f}K<br>P-value: %{customdata:.4f}<extra></extra>',
            customdata=ind_plot_data['P_Value'],
            showlegend=False
        ),
        row=1, col=2
    )
    
    # Add significance stars
    for i, (idx, row) in enumerate(ind_plot_data.iterrows()):
        if row['P_Value'] < 0.001:
            marker = '***'
        elif row['P_Value'] < 0.01:
            marker = '**'
        elif row['P_Value'] < 0.05:
            marker = '*'
        else:
            marker = ''
        
        if marker:
            y_pos = row['DiD_Effect_Mean']/1000
            y_offset = abs(y_pos) * 0.1 + 50
            y_annotation = y_pos + y_offset if y_pos >= 0 else y_pos - y_offset
            
            fig.add_annotation(
                x=row['Industry_Short'],
                y=y_annotation,
                text=f'<b>{marker}</b>',
                showarrow=False,
                font=dict(color='black', size=16),
                row=1, col=2
            )
    
    # Add horizontal line at zero for DiD chart
    fig.add_hline(y=0, line_dash="solid", line_color="black", line_width=1, row=1, col=2)
    
    # Update layout
    fig.update_layout(
        title=dict(
            text='<b>Tariff Impact Analysis: Industries</b>',
            x=0.5,
            font=dict(size=20, color=colors['text'])
        ),
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=-0.3,
            xanchor="center",
            x=0.25
        ),
        plot_bgcolor='white',
        paper_bgcolor='white',
        font=dict(size=12, color=colors['text']),
        height=600,
        width=1400
    )
    
    # Update axes
    fig.update_xaxes(title_text="Industry", row=1, col=1, tickangle=45)
    fig.update_xaxes(title_text="Industry", row=1, col=2, tickangle=45)
    fig.update_yaxes(title_text="Net Buy (Thousands $)", row=1, col=1)
    fig.update_yaxes(title_text="DiD Effect (Thousands $)", row=1, col=2)
    
    # Save as high-quality image
    fig.write_image("industry_analysis.png", width=1400, height=600, scale=2)
    fig.show()

else:
    print("No significant industry changes found for visualization")

# --- Summary Stats for Charts ---
print("\n=== CHART SUMMARY ===")
if len(sec_significant) > 0:
    print(f"Security Types Chart: {len(sec_plot_data)} significant types visualized")
    print("Security types with largest impacts:")
    for _, row in sec_plot_data.head(3).iterrows():
        print(f"  - {row['Security_Type']}: {row['Pct_Change']:+.1f}% change, DiD: ${row['DiD_Effect_Mean']:,.0f}")

if len(ind_significant) > 0:
    print(f"\nIndustry Chart: {len(ind_plot_data)} significant industries visualized")
    print("Industries with largest impacts:")
    for _, row in ind_plot_data.head(3).iterrows():
        print(f"  - {row['Industry'][:30]}: {row['Pct_Change']:+.1f}% change, DiD: ${row['DiD_Effect_Mean']:,.0f}")

print("\nChart files saved:")
print("- security_type_analysis.png (Professional Plotly chart)")
print("- industry_analysis.png (Professional Plotly chart)")
print("\nSignificance markers: *** p<0.001, ** p<0.01, * p<0.05")
