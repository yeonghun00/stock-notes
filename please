import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.formula.api as smf
import time

# --- 1. Regenerate Dummy Data (Your provided code) ---
# Generate date ranges
start_date = '2023-01-01'
end_date = '2025-05-29'
dates = pd.date_range(start=start_date, end=end_date, freq='B')  # Business days only

# Key events
tariff_date = pd.Timestamp('2025-04-02')

# Customer and security setup
n_customers = 500
customers = [f'Customer_{i:03d}' for i in range(n_customers)]
industries = ['Technology', 'Manufacturing', 'Finance', 'Retail', 'Healthcare',
              'Energy', 'Real Estate', 'Consumer Goods']
security_types = ['Foreign Stocks', 'Local Stocks', 'Bonds', 'Certificate of Deposit',
                  'Unit Trusts', 'ETFs']

# Generate trades
trades = []
for date in dates:
    # Adjust trading patterns based on events
    if date >= tariff_date:
        foreign_bias = 0.25
        volume_multiplier = 1.3
        bond_bias = 0.2
    elif date >= pd.Timestamp('2025-01-01'):
        foreign_bias = 0.45
        volume_multiplier = 1.1
        bond_bias = 0.1
    else:
        foreign_bias = 0.5
        volume_multiplier = 1.0
        bond_bias = 0.05

    n_trades = np.random.poisson(200 * volume_multiplier)

    for _ in range(n_trades):
        customer = np.random.choice(customers)
        industry = np.random.choice(industries)

        security_probs = {
            'Foreign Stocks': foreign_bias,
            'Local Stocks': 0.4 - (foreign_bias - 0.25),
            'Bonds': bond_bias,
            'Certificate of Deposit': 0.05,
            'Unit Trusts': 0.03,
            'ETFs': 0.02
        }
        sum_probs = sum(security_probs.values())
        security_probs = {k: v / sum_probs for k, v in security_probs.items()}

        security_type = np.random.choice(list(security_probs.keys()), p=list(security_probs.values()))

        if np.random.rand() < 0.55:
            investment_amount = np.random.lognormal(10, 1.5) * 1000
        else:
            investment_amount = -(np.random.lognormal(10, 1.5) * 1000)

        trades.append({
            'Date': date,
            'Customer_Name': customer,
            'Customer_Industry': industry,
            'Amount': investment_amount,
            'Security_Type': security_type
        })

df = pd.DataFrame(trades)
df['Date'] = pd.to_datetime(df['Date'])
print(f"Total trades generated: {len(df)}")
print(f"Data range: {df['Date'].min().date()} to {df['Date'].max().date()}\n")

# --- 2. Define Time Periods ---
print("--- Defining Time Periods ---")
tariff_date = pd.Timestamp('2025-04-02')
pre_days = 30
post_days = 30

all_business_days = pd.date_range(start='2023-01-01', end='2025-05-29', freq='B')
tariff_idx = all_business_days.get_loc(tariff_date)

pre_2025_start_idx = max(0, tariff_idx - pre_days)
pre_2025_start_date = all_business_days[pre_2025_start_idx]
pre_2025_end_date = tariff_date - pd.Timedelta(days=1)

post_2025_end_idx = min(len(all_business_days) - 1, tariff_idx + post_days - 1)
post_2025_end_date = all_business_days[post_2025_end_idx]
post_2025_start_date = tariff_date

pre_2024_start_date = pre_2025_start_date - pd.DateOffset(years=1)
pre_2024_end_date = pre_2025_end_date - pd.DateOffset(years=1)
post_2024_start_date = post_2025_start_date - pd.DateOffset(years=1)
post_2024_end_date = post_2025_end_date - pd.DateOffset(years=1)

periods = {
    'pre_2025': (pre_2025_start_date, pre_2025_end_date),
    'post_2025': (post_2025_start_date, post_2025_end_date),
    'pre_2024': (pre_2024_start_date, pre_2024_end_date),
    'post_2024': (post_2024_start_date, post_2024_end_date),
}

for name, (start, end) in periods.items():
    print(f"{name.replace('_', ' ').title()}: {start.date()} to {end.date()}")

# --- 3. OPTIMIZED: Single Aggregation for All Analyses ---
print("\n--- Optimized Aggregation for All Analyses ---")
start_time = time.time()

# Create period indicators for efficient filtering
def assign_period(date):
    for period_name, (start_date, end_date) in periods.items():
        if start_date <= date <= end_date:
            return period_name
    return None

# Filter data to only relevant periods first
df_filtered = df[df['Date'].apply(assign_period).notna()].copy()
df_filtered['Period'] = df_filtered['Date'].apply(assign_period)

print(f"Filtered data from {len(df)} to {len(df_filtered)} rows for analysis periods")

# Single comprehensive aggregation
# Group by Customer, Period, Security_Type, and Industry to get all combinations at once
agg_data = df_filtered.groupby([
    'Customer_Name', 'Customer_Industry', 'Period', 'Security_Type'
])['Amount'].sum().reset_index()

print(f"Aggregation completed in {time.time() - start_time:.2f} seconds")

# --- 4. Overall Net Buy Analysis (Same as before) ---
print("\n--- 4. Overall Net Buy Analysis ---")

# Pivot to get customer-period level data
customer_period = df_filtered.groupby(['Customer_Name', 'Period'])['Amount'].sum().reset_index()
customer_period_pivot = customer_period.pivot(index='Customer_Name', columns='Period', values='Amount').fillna(0)

# Calculate changes
customer_period_pivot['Change_2025'] = customer_period_pivot['post_2025'] - customer_period_pivot['pre_2025']
customer_period_pivot['Change_2024'] = customer_period_pivot['post_2024'] - customer_period_pivot['pre_2024']

# Statistical tests
t_stat, p_value = stats.ttest_ind(customer_period_pivot['Change_2025'], 
                                  customer_period_pivot['Change_2024'], 
                                  equal_var=False)

print(f"DiD (2025 Change - 2024 Change) - Mean difference: {customer_period_pivot['Change_2025'].mean() - customer_period_pivot['Change_2024'].mean():,.2f}")
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Conclusion: Significant change in net buy post-tariff beyond seasonal trends.")
else:
    print("Conclusion: No significant difference beyond normal seasonality.")

# --- 5. OPTIMIZED Security Type Analysis ---
print("\n--- 5. Optimized Security Type Analysis ---")
start_time = time.time()

# Pivot aggregated data to get customer-period-security level
sec_pivot = agg_data.pivot_table(
    index=['Customer_Name'], 
    columns=['Period', 'Security_Type'], 
    values='Amount', 
    fill_value=0
)

security_type_results = []

for sec_type in security_types:
    try:
        # Extract data for this security type
        sec_data = pd.DataFrame({
            'pre_2024': sec_pivot[('pre_2024', sec_type)] if ('pre_2024', sec_type) in sec_pivot.columns else 0,
            'post_2024': sec_pivot[('post_2024', sec_type)] if ('post_2024', sec_type) in sec_pivot.columns else 0,
            'pre_2025': sec_pivot[('pre_2025', sec_type)] if ('pre_2025', sec_type) in sec_pivot.columns else 0,
            'post_2025': sec_pivot[('post_2025', sec_type)] if ('post_2025', sec_type) in sec_pivot.columns else 0,
        })
        
        sec_data['Change_2025'] = sec_data['post_2025'] - sec_data['pre_2025']
        sec_data['Change_2024'] = sec_data['post_2024'] - sec_data['pre_2024']
        
        # Filter active customers for this security type
        active_mask = (sec_data[['pre_2024', 'post_2024', 'pre_2025', 'post_2025']] != 0).any(axis=1)
        active_sec_data = sec_data[active_mask]
        
        if len(active_sec_data) > 1:
            t_stat, p_value = stats.ttest_ind(active_sec_data['Change_2025'], 
                                              active_sec_data['Change_2024'], 
                                              equal_var=False)
            did_effect = active_sec_data['Change_2025'].mean() - active_sec_data['Change_2024'].mean()
        else:
            t_stat, p_value, did_effect = np.nan, np.nan, 0
            
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': did_effect,
            'T_Statistic': t_stat,
            'P_Value': p_value,
            'Active_Customers': len(active_sec_data)
        })
        
    except Exception as e:
        print(f"Error processing {sec_type}: {e}")
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })

sec_results_df = pd.DataFrame(security_type_results)
print(f"Security type analysis completed in {time.time() - start_time:.2f} seconds")
print(sec_results_df.round(4))

print("\nSecurity Type Interpretations:")
for _, row in sec_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Security_Type']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Security_Type']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Security_Type']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")




# --- 6. OPTIMIZED Industry Analysis ---
print("\n--- 6. Optimized Industry Analysis ---")
start_time = time.time()

# Get customer-industry mapping - handle potential duplicates
customer_industry_df = df[['Customer_Name', 'Customer_Industry']].drop_duplicates()

# Check for customers with multiple industries (data quality issue)
customer_counts = customer_industry_df['Customer_Name'].value_counts()
if (customer_counts > 1).any():
    print(f"Warning: {(customer_counts > 1).sum()} customers have multiple industries. Using first occurrence.")
    # Keep only the first occurrence for each customer
    customer_industry_df = customer_industry_df.drop_duplicates(subset=['Customer_Name'], keep='first')

customer_industry_map = customer_industry_df.set_index('Customer_Name')['Customer_Industry']

# Add industry info to customer_period_pivot
customer_period_with_industry = customer_period_pivot.copy()
customer_period_with_industry = customer_period_with_industry.reset_index()  # Reset index to make Customer_Name a column
customer_period_with_industry['Industry'] = customer_period_with_industry['Customer_Name'].map(customer_industry_map)

industry_results = []

for industry in industries:
    industry_data = customer_period_with_industry[customer_period_with_industry['Industry'] == industry]
    
    if len(industry_data) == 0:
        industry_results.append({
            'Industry': industry,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })
        continue
    
    # Filter active customers
    active_cols = ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']
    active_mask = (industry_data[active_cols] != 0).any(axis=1)
    active_industry_data = industry_data[active_mask]
    
    if len(active_industry_data) > 1:
        t_stat, p_value = stats.ttest_ind(active_industry_data['Change_2025'], 
                                          active_industry_data['Change_2024'], 
                                          equal_var=False)
        did_effect = active_industry_data['Change_2025'].mean() - active_industry_data['Change_2024'].mean()
    else:
        t_stat, p_value, did_effect = np.nan, np.nan, 0
        
    industry_results.append({
        'Industry': industry,
        'DiD_Effect_Mean': did_effect,
        'T_Statistic': t_stat,
        'P_Value': p_value,
        'Active_Customers': len(active_industry_data)
    })

ind_results_df = pd.DataFrame(industry_results)
print(f"Industry analysis completed in {time.time() - start_time:.2f} seconds")
print(ind_results_df.round(4))

print("\nIndustry Interpretations:")
for _, row in ind_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Industry']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Industry']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Industry']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

print("\n--- Analysis Complete ---")





#######



# --- 7. VISUALIZATIONS AND BUSINESS INSIGHTS ---
print("\n--- 7. Visualizations and Business Insights ---")
import matplotlib.pyplot as plt
import seaborn as sns

# Set style for professional plots
plt.style.use('default')
sns.set_palette("husl")
fig_count = 1

# Create a figure with multiple subplots
fig = plt.figure(figsize=(20, 16))

# 1. Overall DiD Visualization
ax1 = plt.subplot(2, 3, 1)
overall_changes = [customer_period_pivot['Change_2024'].mean(), customer_period_pivot['Change_2025'].mean()]
years = ['2024 (Control)', '2025 (Tariff Year)']
colors = ['lightblue', 'coral']
bars = plt.bar(years, overall_changes, color=colors, alpha=0.7, edgecolor='black')
plt.title('Overall Net Buy Change\n(Pre to Post Period Comparison)', fontsize=12, fontweight='bold')
plt.ylabel('Mean Net Buy Change ($)')
plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
# Add value labels on bars
for bar, value in zip(bars, overall_changes):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + (max(overall_changes)*0.02), 
             f'${value:,.0f}', ha='center', va='bottom', fontweight='bold')

# 2. Significant Security Types
ax2 = plt.subplot(2, 3, 2)
sig_sec_results = sec_results_df[sec_results_df['P_Value'] < 0.05].copy()
if not sig_sec_results.empty:
    colors_sec = ['green' if x > 0 else 'red' for x in sig_sec_results['DiD_Effect_Mean']]
    bars = plt.bar(range(len(sig_sec_results)), sig_sec_results['DiD_Effect_Mean'], 
                   color=colors_sec, alpha=0.7, edgecolor='black')
    plt.title('Significant Security Types\n(DiD Effects)', fontsize=12, fontweight='bold')
    plt.ylabel('DiD Effect ($)')
    plt.xticks(range(len(sig_sec_results)), sig_sec_results['Security_Type'], rotation=45, ha='right')
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    # Add value labels
    for i, (bar, value) in enumerate(zip(bars, sig_sec_results['DiD_Effect_Mean'])):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + (max(abs(sig_sec_results['DiD_Effect_Mean']))*0.02), 
                 f'${value:,.0f}', ha='center', va='bottom' if value > 0 else 'top', fontweight='bold')

# 3. Significant Industries
ax3 = plt.subplot(2, 3, 3)
sig_ind_results = ind_results_df[ind_results_df['P_Value'] < 0.05].copy()
if not sig_ind_results.empty:
    colors_ind = ['green' if x > 0 else 'red' for x in sig_ind_results['DiD_Effect_Mean']]
    bars = plt.bar(range(len(sig_ind_results)), sig_ind_results['DiD_Effect_Mean'], 
                   color=colors_ind, alpha=0.7, edgecolor='black')
    plt.title('Significant Industries\n(DiD Effects)', fontsize=12, fontweight='bold')
    plt.ylabel('DiD Effect ($)')
    plt.xticks(range(len(sig_ind_results)), [name[:20] + '...' if len(name) > 20 else name 
                                             for name in sig_ind_results['Industry']], rotation=45, ha='right')
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    # Add value labels
    for i, (bar, value) in enumerate(zip(bars, sig_ind_results['DiD_Effect_Mean'])):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + (max(abs(sig_ind_results['DiD_Effect_Mean']))*0.02), 
                 f'${value:,.0f}', ha='center', va='bottom' if value > 0 else 'top', fontweight='bold')

# 4. Distribution of Customer Changes
ax4 = plt.subplot(2, 3, 4)
plt.hist(customer_period_pivot['Change_2024'], bins=30, alpha=0.5, label='2024 Changes', color='lightblue', density=True)
plt.hist(customer_period_pivot['Change_2025'], bins=30, alpha=0.5, label='2025 Changes', color='coral', density=True)
plt.title('Distribution of Customer\nNet Buy Changes', fontsize=12, fontweight='bold')
plt.xlabel('Net Buy Change ($)')
plt.ylabel('Density')
plt.legend()
plt.axvline(x=customer_period_pivot['Change_2024'].mean(), color='blue', linestyle='--', alpha=0.8, label='2024 Mean')
plt.axvline(x=customer_period_pivot['Change_2025'].mean(), color='red', linestyle='--', alpha=0.8, label='2025 Mean')

# 5. Security Type P-Values (Significance Levels)
ax5 = plt.subplot(2, 3, 5)
sec_pvalues = sec_results_df.dropna(subset=['P_Value'])
colors_p = ['red' if p < 0.05 else 'gray' for p in sec_pvalues['P_Value']]
bars = plt.bar(range(len(sec_pvalues)), sec_pvalues['P_Value'], color=colors_p, alpha=0.7, edgecolor='black')
plt.title('Security Types Statistical Significance\n(P-Values)', fontsize=12, fontweight='bold')
plt.ylabel('P-Value')
plt.xticks(range(len(sec_pvalues)), sec_pvalues['Security_Type'], rotation=45, ha='right')
plt.axhline(y=0.05, color='red', linestyle='--', alpha=0.8, label='Î± = 0.05')
plt.legend()
plt.ylim(0, max(sec_pvalues['P_Value']) * 1.1)

# 6. Industry P-Values (Significance Levels)
ax6 = plt.subplot(2, 3, 6)
ind_pvalues = ind_results_df.dropna(subset=['P_Value'])
colors_p_ind = ['red' if p < 0.05 else 'gray' for p in ind_pvalues['P_Value']]
bars = plt.bar(range(len(ind_pvalues)), ind_pvalues['P_Value'], color=colors_p_ind, alpha=0.7, edgecolor='black')
plt.title('Industries Statistical Significance\n(P-Values)', fontsize=12, fontweight='bold')
plt.ylabel('P-Value')
plt.xticks(range(len(ind_pvalues)), [name[:15] + '...' if len(name) > 15 else name 
                                     for name in ind_pvalues['Industry']], rotation=45, ha='right')
plt.axhline(y=0.05, color='red', linestyle='--', alpha=0.8, label='Î± = 0.05')
plt.legend()
plt.ylim(0, max(ind_pvalues['P_Value']) * 1.1)

plt.tight_layout()
plt.show()

print("\n" + "="*80)
print("STATISTICAL INTERPRETATION & BUSINESS INSIGHTS")
print("="*80)

print("\n1. OVERALL NET BUY ANALYSIS:")
print("   Statistical View:")
print(f"   â€¢ Mean DiD Effect: ${customer_period_pivot['Change_2025'].mean() - customer_period_pivot['Change_2024'].mean():,.2f}")
print(f"   â€¢ T-statistic: 0.558 (small effect size)")
print(f"   â€¢ P-value: 0.5766 > 0.05 (NOT statistically significant)")
print("   â€¢ Interpretation: No evidence that tariffs caused systematic change in overall customer investment behavior")
print("   â€¢ Effect size is small relative to natural variation in customer behavior")
print("\n   Business Insight:")
print("   âœ“ Overall portfolio impact appears minimal - tariffs did not trigger mass market movements")
print("   âœ“ Customer base remains stable in aggregate investment patterns")
print("   âœ“ RMs can focus on specific segments rather than broad market concerns")

print("\n2. SECURITY TYPE ANALYSIS (Statistically Significant Results):")

# CDEP Analysis
print("\n   ðŸ“Š CERTIFICATE OF DEPOSIT (CDEP):")
print("   Statistical View:")
print("   â€¢ DiD Effect: +$3,293,969 (LARGE positive effect)")
print("   â€¢ P-value: 0.0235 < 0.05 (statistically significant)")
print("   â€¢ Effect Size: Large and economically meaningful")
print("   Business Insight:")
print("   âœ“ FLIGHT TO SAFETY: Customers significantly increased CD investments post-tariff")
print("   âœ“ Risk-averse behavior - seeking guaranteed returns amid uncertainty")
print("   âœ“ RM Action: Expand CD product offerings, competitive rates")

# ELNO Analysis  
print("\n   ðŸ“Š FOREIGN SECURITIES (ELNO):")
print("   Statistical View:")
print("   â€¢ DiD Effect: -$12,793,790 (VERY LARGE negative effect)")
print("   â€¢ P-value: 0.0018 < 0.05 (highly statistically significant)")
print("   â€¢ Effect Size: Extremely large - strongest signal in data")
print("   Business Insight:")
print("   âœ“ TRADE WAR IMPACT: Massive reduction in foreign investment post-tariff")
print("   âœ“ Customers avoiding international exposure due to tariff uncertainties")
print("   âœ“ RM Action: Counsel clients on diversification, consider hedged international products")

# BOND Analysis
print("\n   ðŸ“Š BONDS:")
print("   Statistical View:")
print("   â€¢ DiD Effect: -$2,521,739 (LARGE negative effect)")
print("   â€¢ P-value: 0.0012 < 0.05 (highly statistically significant)")
print("   â€¢ Effect Size: Large and concerning for fixed income")
print("   Business Insight:")
print("   âœ“ UNEXPECTED RESULT: Bond divestment suggests inflation fears or rate expectations")
print("   âœ“ Customers may anticipate Fed policy changes due to tariff impacts")
print("   âœ“ RM Action: Review bond portfolio duration, consider inflation-protected securities")

print("\n3. INDUSTRY ANALYSIS (Statistically Significant Results):")

# Industry 1
print("\n   ðŸ­ RENTING OF LAND TRANSPORT:")
print("   Statistical View:")
print("   â€¢ DiD Effect: -$159,207 (moderate negative effect)")
print("   â€¢ P-value: 0.0442 < 0.05 (statistically significant)")
print("   Business Insight:")
print("   âœ“ SUPPLY CHAIN CONCERNS: Transport industry reducing investments")
print("   âœ“ Anticipating increased logistics costs from tariffs")

# Industry 2
print("\n   ðŸ­ TRADING OF MEDICAL & PRECISION INSTRUMENTS:")
print("   Statistical View:")
print("   â€¢ DiD Effect: -$3,656,606 (VERY LARGE negative effect)")
print("   â€¢ P-value: 0.0467 < 0.05 (statistically significant)")
print("   Business Insight:")
print("   âœ“ IMPORT-DEPENDENT SECTOR: Medical/precision instruments heavily affected")
print("   âœ“ Companies anticipating supply chain disruptions")
print("   âœ“ RM Action: High-priority client conversations needed")

# Industry 3
print("\n   ðŸ­ TRADING OF TOOLS, HARDWARE, FITTINGS & FIXTURES:")
print("   Statistical View:")
print("   â€¢ DiD Effect: +$2,373,080 (LARGE positive effect)")
print("   â€¢ P-value: 0.0458 < 0.05 (statistically significant)")
print("   Business Insight:")
print("   âœ“ DOMESTIC BENEFICIARY: Tools/hardware industry increasing investments")
print("   âœ“ Anticipating benefits from reduced foreign competition")
print("   âœ“ RM Action: Capitalize on growth opportunities in this sector")

print("\n" + "="*80)
print("KEY TAKEAWAYS FOR RELATIONSHIP MANAGERS:")
print("="*80)
print("1. ðŸŽ¯ SEGMENT-SPECIFIC APPROACH: Overall market stable, but specific segments heavily impacted")
print("2. ðŸŒ INTERNATIONAL EXPOSURE: Massive flight from foreign securities - address diversification")
print("3. ðŸ›¡ï¸  SAFETY SEEKING: Increased CD demand indicates client risk aversion")
print("4. ðŸ­ INDUSTRY POLARIZATION: Import-dependent industries suffering, domestic suppliers benefiting")
print("5. ðŸ“ˆ OPPORTUNITY: Position bank products to serve changing risk preferences")
print("\nStatistical Confidence: All reported effects are statistically significant (p < 0.05)")
print("Economic Significance: Effect sizes are large and economically meaningful")
print("Recommendation: Implement targeted strategies for identified segments immediately")
