import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.formula.api as smf
import time

# --- 1. Regenerate Dummy Data (Your provided code) ---
# Generate date ranges
start_date = '2023-01-01'
end_date = '2025-05-29'
dates = pd.date_range(start=start_date, end=end_date, freq='B')  # Business days only

# Key events
tariff_date = pd.Timestamp('2025-04-02')

# Customer and security setup
n_customers = 500
customers = [f'Customer_{i:03d}' for i in range(n_customers)]
industries = ['Technology', 'Manufacturing', 'Finance', 'Retail', 'Healthcare',
              'Energy', 'Real Estate', 'Consumer Goods']
security_types = ['Foreign Stocks', 'Local Stocks', 'Bonds', 'Certificate of Deposit',
                  'Unit Trusts', 'ETFs']

# Generate trades
trades = []
for date in dates:
    # Adjust trading patterns based on events
    if date >= tariff_date:
        foreign_bias = 0.25
        volume_multiplier = 1.3
        bond_bias = 0.2
    elif date >= pd.Timestamp('2025-01-01'):
        foreign_bias = 0.45
        volume_multiplier = 1.1
        bond_bias = 0.1
    else:
        foreign_bias = 0.5
        volume_multiplier = 1.0
        bond_bias = 0.05

    n_trades = np.random.poisson(200 * volume_multiplier)

    for _ in range(n_trades):
        customer = np.random.choice(customers)
        industry = np.random.choice(industries)

        security_probs = {
            'Foreign Stocks': foreign_bias,
            'Local Stocks': 0.4 - (foreign_bias - 0.25),
            'Bonds': bond_bias,
            'Certificate of Deposit': 0.05,
            'Unit Trusts': 0.03,
            'ETFs': 0.02
        }
        sum_probs = sum(security_probs.values())
        security_probs = {k: v / sum_probs for k, v in security_probs.items()}

        security_type = np.random.choice(list(security_probs.keys()), p=list(security_probs.values()))

        if np.random.rand() < 0.55:
            investment_amount = np.random.lognormal(10, 1.5) * 1000
        else:
            investment_amount = -(np.random.lognormal(10, 1.5) * 1000)

        trades.append({
            'Date': date,
            'Customer_Name': customer,
            'Customer_Industry': industry,
            'Amount': investment_amount,
            'Security_Type': security_type
        })

df = pd.DataFrame(trades)
df['Date'] = pd.to_datetime(df['Date'])
print(f"Total trades generated: {len(df)}")
print(f"Data range: {df['Date'].min().date()} to {df['Date'].max().date()}\n")

# --- 2. Define Time Periods ---
print("--- Defining Time Periods ---")
tariff_date = pd.Timestamp('2025-04-02')
pre_days = 30
post_days = 30

all_business_days = pd.date_range(start='2023-01-01', end='2025-05-29', freq='B')
tariff_idx = all_business_days.get_loc(tariff_date)

pre_2025_start_idx = max(0, tariff_idx - pre_days)
pre_2025_start_date = all_business_days[pre_2025_start_idx]
pre_2025_end_date = tariff_date - pd.Timedelta(days=1)

post_2025_end_idx = min(len(all_business_days) - 1, tariff_idx + post_days - 1)
post_2025_end_date = all_business_days[post_2025_end_idx]
post_2025_start_date = tariff_date

pre_2024_start_date = pre_2025_start_date - pd.DateOffset(years=1)
pre_2024_end_date = pre_2025_end_date - pd.DateOffset(years=1)
post_2024_start_date = post_2025_start_date - pd.DateOffset(years=1)
post_2024_end_date = post_2025_end_date - pd.DateOffset(years=1)

periods = {
    'pre_2025': (pre_2025_start_date, pre_2025_end_date),
    'post_2025': (post_2025_start_date, post_2025_end_date),
    'pre_2024': (pre_2024_start_date, pre_2024_end_date),
    'post_2024': (post_2024_start_date, post_2024_end_date),
}

for name, (start, end) in periods.items():
    print(f"{name.replace('_', ' ').title()}: {start.date()} to {end.date()}")

# --- 3. OPTIMIZED: Single Aggregation for All Analyses ---
print("\n--- Optimized Aggregation for All Analyses ---")
start_time = time.time()

# Create period indicators for efficient filtering
def assign_period(date):
    for period_name, (start_date, end_date) in periods.items():
        if start_date <= date <= end_date:
            return period_name
    return None

# Filter data to only relevant periods first
df_filtered = df[df['Date'].apply(assign_period).notna()].copy()
df_filtered['Period'] = df_filtered['Date'].apply(assign_period)

print(f"Filtered data from {len(df)} to {len(df_filtered)} rows for analysis periods")

# Single comprehensive aggregation
# Group by Customer, Period, Security_Type, and Industry to get all combinations at once
agg_data = df_filtered.groupby([
    'Customer_Name', 'Customer_Industry', 'Period', 'Security_Type'
])['Amount'].sum().reset_index()

print(f"Aggregation completed in {time.time() - start_time:.2f} seconds")

# --- 4. Overall Net Buy Analysis (Same as before) ---
print("\n--- 4. Overall Net Buy Analysis ---")

# Pivot to get customer-period level data
customer_period = df_filtered.groupby(['Customer_Name', 'Period'])['Amount'].sum().reset_index()
customer_period_pivot = customer_period.pivot(index='Customer_Name', columns='Period', values='Amount').fillna(0)

# Calculate changes
customer_period_pivot['Change_2025'] = customer_period_pivot['post_2025'] - customer_period_pivot['pre_2025']
customer_period_pivot['Change_2024'] = customer_period_pivot['post_2024'] - customer_period_pivot['pre_2024']

# Statistical tests
t_stat, p_value = stats.ttest_ind(customer_period_pivot['Change_2025'], 
                                  customer_period_pivot['Change_2024'], 
                                  equal_var=False)

print(f"DiD (2025 Change - 2024 Change) - Mean difference: {customer_period_pivot['Change_2025'].mean() - customer_period_pivot['Change_2024'].mean():,.2f}")
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Conclusion: Significant change in net buy post-tariff beyond seasonal trends.")
else:
    print("Conclusion: No significant difference beyond normal seasonality.")

# --- 5. OPTIMIZED Security Type Analysis ---
print("\n--- 5. Optimized Security Type Analysis ---")
start_time = time.time()

# Pivot aggregated data to get customer-period-security level
sec_pivot = agg_data.pivot_table(
    index=['Customer_Name'], 
    columns=['Period', 'Security_Type'], 
    values='Amount', 
    fill_value=0
)

security_type_results = []

for sec_type in security_types:
    try:
        # Extract data for this security type
        sec_data = pd.DataFrame({
            'pre_2024': sec_pivot[('pre_2024', sec_type)] if ('pre_2024', sec_type) in sec_pivot.columns else 0,
            'post_2024': sec_pivot[('post_2024', sec_type)] if ('post_2024', sec_type) in sec_pivot.columns else 0,
            'pre_2025': sec_pivot[('pre_2025', sec_type)] if ('pre_2025', sec_type) in sec_pivot.columns else 0,
            'post_2025': sec_pivot[('post_2025', sec_type)] if ('post_2025', sec_type) in sec_pivot.columns else 0,
        })
        
        sec_data['Change_2025'] = sec_data['post_2025'] - sec_data['pre_2025']
        sec_data['Change_2024'] = sec_data['post_2024'] - sec_data['pre_2024']
        
        # Filter active customers for this security type
        active_mask = (sec_data[['pre_2024', 'post_2024', 'pre_2025', 'post_2025']] != 0).any(axis=1)
        active_sec_data = sec_data[active_mask]
        
        if len(active_sec_data) > 1:
            t_stat, p_value = stats.ttest_ind(active_sec_data['Change_2025'], 
                                              active_sec_data['Change_2024'], 
                                              equal_var=False)
            did_effect = active_sec_data['Change_2025'].mean() - active_sec_data['Change_2024'].mean()
        else:
            t_stat, p_value, did_effect = np.nan, np.nan, 0
            
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': did_effect,
            'T_Statistic': t_stat,
            'P_Value': p_value,
            'Active_Customers': len(active_sec_data)
        })
        
    except Exception as e:
        print(f"Error processing {sec_type}: {e}")
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })

sec_results_df = pd.DataFrame(security_type_results)
print(f"Security type analysis completed in {time.time() - start_time:.2f} seconds")
print(sec_results_df.round(4))

print("\nSecurity Type Interpretations:")
for _, row in sec_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Security_Type']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Security_Type']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Security_Type']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

# --- 6. OPTIMIZED Industry Analysis ---
print("\n--- 6. Optimized Industry Analysis ---")
start_time = time.time()

# Get customer-industry mapping
customer_industry_map = df[['Customer_Name', 'Customer_Industry']].drop_duplicates().set_index('Customer_Name')['Customer_Industry']

# Add industry info to customer_period_pivot
customer_period_with_industry = customer_period_pivot.copy()
customer_period_with_industry['Industry'] = customer_period_with_industry.index.map(customer_industry_map)

industry_results = []

for industry in industries:
    industry_data = customer_period_with_industry[customer_period_with_industry['Industry'] == industry]
    
    # Filter active customers
    active_cols = ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']
    active_mask = (industry_data[active_cols] != 0).any(axis=1)
    active_industry_data = industry_data[active_mask]
    
    if len(active_industry_data) > 1:
        t_stat, p_value = stats.ttest_ind(active_industry_data['Change_2025'], 
                                          active_industry_data['Change_2024'], 
                                          equal_var=False)
        did_effect = active_industry_data['Change_2025'].mean() - active_industry_data['Change_2024'].mean()
    else:
        t_stat, p_value, did_effect = np.nan, np.nan, 0
        
    industry_results.append({
        'Industry': industry,
        'DiD_Effect_Mean': did_effect,
        'T_Statistic': t_stat,
        'P_Value': p_value,
        'Active_Customers': len(active_industry_data)
    })

ind_results_df = pd.DataFrame(industry_results)
print(f"Industry analysis completed in {time.time() - start_time:.2f} seconds")
print(ind_results_df.round(4))

print("\nIndustry Interpretations:")
for _, row in ind_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Industry']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Industry']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Industry']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

print("\n--- Analysis Complete ---")
