import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.formula.api as smf
import time

# --- 1. Regenerate Dummy Data (Your provided code) ---
# Generate date ranges
start_date = '2023-01-01'
end_date = '2025-05-29'
dates = pd.date_range(start=start_date, end=end_date, freq='B')  # Business days only

# Key events
tariff_date = pd.Timestamp('2025-04-02')

# Customer and security setup
n_customers = 500
customers = [f'Customer_{i:03d}' for i in range(n_customers)]
industries = ['Technology', 'Manufacturing', 'Finance', 'Retail', 'Healthcare',
              'Energy', 'Real Estate', 'Consumer Goods']
security_types = ['Foreign Stocks', 'Local Stocks', 'Bonds', 'Certificate of Deposit',
                  'Unit Trusts', 'ETFs']

# Generate trades
trades = []
for date in dates:
    # Adjust trading patterns based on events
    if date >= tariff_date:
        foreign_bias = 0.25
        volume_multiplier = 1.3
        bond_bias = 0.2
    elif date >= pd.Timestamp('2025-01-01'):
        foreign_bias = 0.45
        volume_multiplier = 1.1
        bond_bias = 0.1
    else:
        foreign_bias = 0.5
        volume_multiplier = 1.0
        bond_bias = 0.05

    n_trades = np.random.poisson(200 * volume_multiplier)

    for _ in range(n_trades):
        customer = np.random.choice(customers)
        industry = np.random.choice(industries)

        security_probs = {
            'Foreign Stocks': foreign_bias,
            'Local Stocks': 0.4 - (foreign_bias - 0.25),
            'Bonds': bond_bias,
            'Certificate of Deposit': 0.05,
            'Unit Trusts': 0.03,
            'ETFs': 0.02
        }
        sum_probs = sum(security_probs.values())
        security_probs = {k: v / sum_probs for k, v in security_probs.items()}

        security_type = np.random.choice(list(security_probs.keys()), p=list(security_probs.values()))

        if np.random.rand() < 0.55:
            investment_amount = np.random.lognormal(10, 1.5) * 1000
        else:
            investment_amount = -(np.random.lognormal(10, 1.5) * 1000)

        trades.append({
            'Date': date,
            'Customer_Name': customer,
            'Customer_Industry': industry,
            'Amount': investment_amount,
            'Security_Type': security_type
        })

df = pd.DataFrame(trades)
df['Date'] = pd.to_datetime(df['Date'])
print(f"Total trades generated: {len(df)}")
print(f"Data range: {df['Date'].min().date()} to {df['Date'].max().date()}\n")

# --- 2. Define Time Periods ---
print("--- Defining Time Periods ---")
tariff_date = pd.Timestamp('2025-04-02')
pre_days = 30
post_days = 30

all_business_days = pd.date_range(start='2023-01-01', end='2025-05-29', freq='B')
tariff_idx = all_business_days.get_loc(tariff_date)

pre_2025_start_idx = max(0, tariff_idx - pre_days)
pre_2025_start_date = all_business_days[pre_2025_start_idx]
pre_2025_end_date = tariff_date - pd.Timedelta(days=1)

post_2025_end_idx = min(len(all_business_days) - 1, tariff_idx + post_days - 1)
post_2025_end_date = all_business_days[post_2025_end_idx]
post_2025_start_date = tariff_date

pre_2024_start_date = pre_2025_start_date - pd.DateOffset(years=1)
pre_2024_end_date = pre_2025_end_date - pd.DateOffset(years=1)
post_2024_start_date = post_2025_start_date - pd.DateOffset(years=1)
post_2024_end_date = post_2025_end_date - pd.DateOffset(years=1)

periods = {
    'pre_2025': (pre_2025_start_date, pre_2025_end_date),
    'post_2025': (post_2025_start_date, post_2025_end_date),
    'pre_2024': (pre_2024_start_date, pre_2024_end_date),
    'post_2024': (post_2024_start_date, post_2024_end_date),
}

for name, (start, end) in periods.items():
    print(f"{name.replace('_', ' ').title()}: {start.date()} to {end.date()}")

# --- 3. OPTIMIZED: Single Aggregation for All Analyses ---
print("\n--- Optimized Aggregation for All Analyses ---")
start_time = time.time()

# Create period indicators for efficient filtering
def assign_period(date):
    for period_name, (start_date, end_date) in periods.items():
        if start_date <= date <= end_date:
            return period_name
    return None

# Filter data to only relevant periods first
df_filtered = df[df['Date'].apply(assign_period).notna()].copy()
df_filtered['Period'] = df_filtered['Date'].apply(assign_period)

print(f"Filtered data from {len(df)} to {len(df_filtered)} rows for analysis periods")

# Single comprehensive aggregation
# Group by Customer, Period, Security_Type, and Industry to get all combinations at once
agg_data = df_filtered.groupby([
    'Customer_Name', 'Customer_Industry', 'Period', 'Security_Type'
])['Amount'].sum().reset_index()

print(f"Aggregation completed in {time.time() - start_time:.2f} seconds")

# --- 4. Overall Net Buy Analysis (Same as before) ---
print("\n--- 4. Overall Net Buy Analysis ---")

# Pivot to get customer-period level data
customer_period = df_filtered.groupby(['Customer_Name', 'Period'])['Amount'].sum().reset_index()
customer_period_pivot = customer_period.pivot(index='Customer_Name', columns='Period', values='Amount').fillna(0)

# Calculate changes
customer_period_pivot['Change_2025'] = customer_period_pivot['post_2025'] - customer_period_pivot['pre_2025']
customer_period_pivot['Change_2024'] = customer_period_pivot['post_2024'] - customer_period_pivot['pre_2024']

# Statistical tests
t_stat, p_value = stats.ttest_ind(customer_period_pivot['Change_2025'], 
                                  customer_period_pivot['Change_2024'], 
                                  equal_var=False)

print(f"DiD (2025 Change - 2024 Change) - Mean difference: {customer_period_pivot['Change_2025'].mean() - customer_period_pivot['Change_2024'].mean():,.2f}")
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("Conclusion: Significant change in net buy post-tariff beyond seasonal trends.")
else:
    print("Conclusion: No significant difference beyond normal seasonality.")

# --- 5. OPTIMIZED Security Type Analysis ---
print("\n--- 5. Optimized Security Type Analysis ---")
start_time = time.time()

# Pivot aggregated data to get customer-period-security level
sec_pivot = agg_data.pivot_table(
    index=['Customer_Name'], 
    columns=['Period', 'Security_Type'], 
    values='Amount', 
    fill_value=0
)

security_type_results = []

for sec_type in security_types:
    try:
        # Extract data for this security type
        sec_data = pd.DataFrame({
            'pre_2024': sec_pivot[('pre_2024', sec_type)] if ('pre_2024', sec_type) in sec_pivot.columns else 0,
            'post_2024': sec_pivot[('post_2024', sec_type)] if ('post_2024', sec_type) in sec_pivot.columns else 0,
            'pre_2025': sec_pivot[('pre_2025', sec_type)] if ('pre_2025', sec_type) in sec_pivot.columns else 0,
            'post_2025': sec_pivot[('post_2025', sec_type)] if ('post_2025', sec_type) in sec_pivot.columns else 0,
        })
        
        sec_data['Change_2025'] = sec_data['post_2025'] - sec_data['pre_2025']
        sec_data['Change_2024'] = sec_data['post_2024'] - sec_data['pre_2024']
        
        # Filter active customers for this security type
        active_mask = (sec_data[['pre_2024', 'post_2024', 'pre_2025', 'post_2025']] != 0).any(axis=1)
        active_sec_data = sec_data[active_mask]
        
        if len(active_sec_data) > 1:
            t_stat, p_value = stats.ttest_ind(active_sec_data['Change_2025'], 
                                              active_sec_data['Change_2024'], 
                                              equal_var=False)
            did_effect = active_sec_data['Change_2025'].mean() - active_sec_data['Change_2024'].mean()
        else:
            t_stat, p_value, did_effect = np.nan, np.nan, 0
            
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': did_effect,
            'T_Statistic': t_stat,
            'P_Value': p_value,
            'Active_Customers': len(active_sec_data)
        })
        
    except Exception as e:
        print(f"Error processing {sec_type}: {e}")
        security_type_results.append({
            'Security_Type': sec_type,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })

sec_results_df = pd.DataFrame(security_type_results)
print(f"Security type analysis completed in {time.time() - start_time:.2f} seconds")
print(sec_results_df.round(4))

print("\nSecurity Type Interpretations:")
for _, row in sec_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Security_Type']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Security_Type']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Security_Type']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")




# --- 6. OPTIMIZED Industry Analysis ---
print("\n--- 6. Optimized Industry Analysis ---")
start_time = time.time()

# Get customer-industry mapping - handle potential duplicates
customer_industry_df = df[['Customer_Name', 'Customer_Industry']].drop_duplicates()

# Check for customers with multiple industries (data quality issue)
customer_counts = customer_industry_df['Customer_Name'].value_counts()
if (customer_counts > 1).any():
    print(f"Warning: {(customer_counts > 1).sum()} customers have multiple industries. Using first occurrence.")
    # Keep only the first occurrence for each customer
    customer_industry_df = customer_industry_df.drop_duplicates(subset=['Customer_Name'], keep='first')

customer_industry_map = customer_industry_df.set_index('Customer_Name')['Customer_Industry']

# Add industry info to customer_period_pivot
customer_period_with_industry = customer_period_pivot.copy()
customer_period_with_industry = customer_period_with_industry.reset_index()  # Reset index to make Customer_Name a column
customer_period_with_industry['Industry'] = customer_period_with_industry['Customer_Name'].map(customer_industry_map)

industry_results = []

for industry in industries:
    industry_data = customer_period_with_industry[customer_period_with_industry['Industry'] == industry]
    
    if len(industry_data) == 0:
        industry_results.append({
            'Industry': industry,
            'DiD_Effect_Mean': 0,
            'T_Statistic': np.nan,
            'P_Value': np.nan,
            'Active_Customers': 0
        })
        continue
    
    # Filter active customers
    active_cols = ['pre_2024', 'post_2024', 'pre_2025', 'post_2025']
    active_mask = (industry_data[active_cols] != 0).any(axis=1)
    active_industry_data = industry_data[active_mask]
    
    if len(active_industry_data) > 1:
        t_stat, p_value = stats.ttest_ind(active_industry_data['Change_2025'], 
                                          active_industry_data['Change_2024'], 
                                          equal_var=False)
        did_effect = active_industry_data['Change_2025'].mean() - active_industry_data['Change_2024'].mean()
    else:
        t_stat, p_value, did_effect = np.nan, np.nan, 0
        
    industry_results.append({
        'Industry': industry,
        'DiD_Effect_Mean': did_effect,
        'T_Statistic': t_stat,
        'P_Value': p_value,
        'Active_Customers': len(active_industry_data)
    })

ind_results_df = pd.DataFrame(industry_results)
print(f"Industry analysis completed in {time.time() - start_time:.2f} seconds")
print(ind_results_df.round(4))

print("\nIndustry Interpretations:")
for _, row in ind_results_df.iterrows():
    if pd.notna(row['P_Value']) and row['P_Value'] < 0.05:
        print(f"  - {row['Industry']}: Significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")
    elif row['Active_Customers'] < 2:
        print(f"  - {row['Industry']}: Insufficient data ({row['Active_Customers']} active customers)")
    else:
        print(f"  - {row['Industry']}: No significant impact (DiD: {row['DiD_Effect_Mean']:,.0f}, p={row['P_Value']:.4f})")

print("\n--- Analysis Complete ---")





#######


# --- 7. VISUALIZATIONS FOR PRESENTATION ---
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

print("\n--- Creating Presentation Visualizations ---")

# === SLIDE 3: OVERALL ANALYSIS VISUALIZATION ===
print("Creating Overall Analysis Chart...")

# Calculate daily aggregates for time series
daily_data = df_filtered.groupby(['Date', 'Period'])['Amount'].sum().reset_index()
daily_pivot = daily_data.pivot(index='Date', columns='Period', values='Amount').fillna(0)

# Create the overall trends chart
fig_overall = go.Figure()

# Add 2024 periods
fig_overall.add_trace(go.Scatter(
    x=daily_pivot.index[daily_pivot['pre_2024'].notna()],
    y=daily_pivot['pre_2024'].dropna(),
    mode='lines+markers',
    name='2024 Pre-Period',
    line=dict(color='lightblue', width=2),
    marker=dict(size=4)
))

fig_overall.add_trace(go.Scatter(
    x=daily_pivot.index[daily_pivot['post_2024'].notna()],
    y=daily_pivot['post_2024'].dropna(),
    mode='lines+markers',
    name='2024 Post-Period',
    line=dict(color='blue', width=2),
    marker=dict(size=4)
))

# Add 2025 periods
fig_overall.add_trace(go.Scatter(
    x=daily_pivot.index[daily_pivot['pre_2025'].notna()],
    y=daily_pivot['pre_2025'].dropna(),
    mode='lines+markers',
    name='2025 Pre-Tariff',
    line=dict(color='lightcoral', width=2),
    marker=dict(size=4)
))

fig_overall.add_trace(go.Scatter(
    x=daily_pivot.index[daily_pivot['post_2025'].notna()],
    y=daily_pivot['post_2025'].dropna(),
    mode='lines+markers',
    name='2025 Post-Tariff',
    line=dict(color='red', width=3),
    marker=dict(size=6)
))

# Add vertical line for tariff date
fig_overall.add_vline(x=tariff_date, line_dash="dash", line_color="black", 
                     annotation_text="Tariff Implemented", annotation_position="top")

fig_overall.update_layout(
    title="Overall Customer Net Buy: No Significant Change<br><sub>P-value: 0.58 (Not Statistically Significant)</sub>",
    xaxis_title="Date",
    yaxis_title="Daily Net Buy ($)",
    hovermode='x unified',
    template='plotly_white',
    width=900,
    height=500
)

fig_overall.show()

# === SLIDE 4: SECURITY TYPE ANALYSIS VISUALIZATION ===
print("Creating Security Type Analysis Chart...")

# Filter significant results only
sig_security = sec_results_df[sec_results_df['P_Value'] < 0.05].copy()
sig_security = sig_security.sort_values('DiD_Effect_Mean')

# Create color mapping
colors = ['red' if x < 0 else 'green' for x in sig_security['DiD_Effect_Mean']]

fig_security = go.Figure(data=[
    go.Bar(
        x=sig_security['DiD_Effect_Mean'],
        y=sig_security['Security_Type'],
        orientation='h',
        marker_color=colors,
        text=[f"${x:,.0f}" for x in sig_security['DiD_Effect_Mean']],
        textposition='outside',
        hovertemplate='<b>%{y}</b><br>Impact: $%{x:,.0f}<br>P-value: %{customdata:.4f}<extra></extra>',
        customdata=sig_security['P_Value']
    )
])

fig_security.update_layout(
    title="Security Type Impact: Flight to Safety Pattern<br><sub>Certificate of Deposits ↑ | Foreign Stocks ↓ | Bonds ↓</sub>",
    xaxis_title="Net Buy Change ($) - Tariff Impact",
    yaxis_title="Security Type",
    template='plotly_white',
    width=900,
    height=400,
    xaxis=dict(tickformat='$,.0f')
)

# Add zero line
fig_security.add_vline(x=0, line_dash="dot", line_color="gray")

fig_security.show()

# === SLIDE 5: INDUSTRY ANALYSIS VISUALIZATION ===
print("Creating Industry Analysis Chart...")

# Filter significant results only
sig_industry = ind_results_df[ind_results_df['P_Value'] < 0.05].copy()
sig_industry = sig_industry.sort_values('DiD_Effect_Mean')

# Create color mapping
colors_ind = ['red' if x < 0 else 'green' for x in sig_industry['DiD_Effect_Mean']]

fig_industry = go.Figure(data=[
    go.Bar(
        x=sig_industry['DiD_Effect_Mean'],
        y=sig_industry['Industry'],
        orientation='h',
        marker_color=colors_ind,
        text=[f"${x:,.0f}" for x in sig_industry['DiD_Effect_Mean']],
        textposition='outside',
        hovertemplate='<b>%{y}</b><br>Impact: $%{x:,.0f}<br>P-value: %{customdata:.4f}<extra></extra>',
        customdata=sig_industry['P_Value']
    )
])

fig_industry.update_layout(
    title="Industry Impact: Targeted Effects<br><sub>Transport & Medical Equipment Hit | Tools & Hardware Benefit</sub>",
    xaxis_title="Net Buy Change ($) - Tariff Impact",
    yaxis_title="Industry",
    template='plotly_white',
    width=900,
    height=400,
    xaxis=dict(tickformat='$,.0f')
)

# Add zero line
fig_industry.add_vline(x=0, line_dash="dot", line_color="gray")

fig_industry.show()

# === SUMMARY STATISTICS TABLE ===
print("Creating Summary Statistics...")

summary_stats = pd.DataFrame({
    'Analysis': ['Overall Net Buy', 'Security Types (Significant)', 'Industries (Significant)'],
    'P-Value': [0.5766, f"{sig_security['P_Value'].mean():.4f} avg", f"{sig_industry['P_Value'].mean():.4f} avg"],
    'Key Finding': [
        'No significant change',
        f'{len(sig_security)} types significantly affected',
        f'{len(sig_industry)} industries significantly affected'
    ],
    'Business Impact': [
        'Aggregate stability',
        'Flight to safety pattern',
        'Targeted sector effects'
    ]
})

print("\nSummary Table for Presentation:")
print(summary_stats.to_string(index=False))

print("\n--- Visualization Creation Complete ---")
print("Charts are ready for your PowerPoint presentation!")
print("\nKey Messages:")
print("1. Overall: Statistically stable (p=0.58)")
print(f"2. Security Types: {len(sig_security)} significantly affected - flight to safety")
print(f"3. Industries: {len(sig_industry)} targeted impacts - actionable for RMs")
